{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "### <b>Table of Content</b>\n",
    "\n",
    "0. Background\n",
    "\n",
    "1. Import functions\n",
    "\n",
    "2. Load data\n",
    "\n",
    "3. Explore data<br>\n",
    "    3-1. Examine and transform data formats<br>\n",
    "    3-2. Plot histograms and box plots<br>\n",
    "    3-3. Plot a correlation heatmap<br>\n",
    "    3-4. Plot seasonal decomposition<br>\n",
    "    3-5. Plot autocorrelations\n",
    "\n",
    "4. first, build a voice cloning system given a speaker’s spoken audio that clones the source speaker’s voice to the target speaker’s voice\n",
    "    4-1. For the voice cloning system (VC), you can utilize the TIMIT dataset as it consists of aligned text-audio data with various speakers.\n",
    "    4-2. Use Word Error Rate (WER) for automatic evaluation of the voice cloning (VC) system for the speech generation part\n",
    "    https://medium.com/ibm-watson-speech-services/new-python-scripts-to-measure-word-error-rate-on-watson-speech-to-text-77ecaa513f60\n",
    "    https://github.com/jitsi/jiwer\n",
    "    &emsp; 4-2-1. speech to text\n",
    "    &emsp; 4-2-2. measure WER using the original script and transcribed text\n",
    "    4-3. also report speaker classification accuracy to assess the performance of the generated audio’s target speaker.\n",
    "\n",
    "5. Next, build a machine learning system which detects if any spoken audio is a natural speech or synthetically generated by machine.\n",
    "    5-1. For the fake audio detection system (FAD) you can utilize the CommonVoice dataset as it consists of thousands of naturally spoken audio which could be used as golden spoken audio by humans as positive examples and creating negative examples using the voice cloning system as automatic data/label generator.\n",
    "    5-2. For the fake audio detection (FAD) system evaluate the performance of the models using F-score via positive labels coming from the groundtruth dataset and negative labels generated by the VC.\n",
    "\n",
    "\n",
    "\n",
    "4. Select and engineer features\n",
    "\n",
    "5. Train models<br>\n",
    "    5-1. Split data into train and test sets<br>\n",
    "    5-2. SARIMAX model<br>\n",
    "    &emsp; 5-2-1. Perform stepwise search<br>\n",
    "    &emsp; 5-2-2. Train with best orders<br>\n",
    "    5-3. Train and evaluate different models<br>\n",
    "    &emsp; 5-3-1. Train three different models<br>\n",
    "    &emsp; 5-3-2. Compare model performance\n",
    "\n",
    "6. Evaluate prediction results<br>\n",
    "    6-1. Create Bollinger Bands<br>\n",
    "    6-2. Get trading dates with different intervals<br>\n",
    "    6-3. Make training decisions and get capital returns<br>\n",
    "    &emsp; 6-3-1. Based on SARIMAX predictions<br>\n",
    "    &emsp; 6-3-2. Based on Bollinger Band\n",
    "\n",
    "7. Build pipeline and process all stock data<br>\n",
    "    7-1. Interpret results<br>\n",
    "    &emsp; 7-1-1. Capital returns<br>\n",
    "    &emsp; 7-1-2. Model performance\n",
    "\n",
    "8. Conclusion\n",
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>0. Background</b>\n",
    "\n",
    "This project is for a cyber security company providing products and services that can detect whether audio and video media is authentic or fake.\n",
    "\n",
    "We are given two publically available corpora of speech data, which are the <a href=\"https://github.com/philipperemy/timit\">TIMIT</a> and <a href=\"https://commonvoice.mozilla.org/en/datasets\">CommonVoice</a> datasets. We will build two machine learning systems using these datasets as follows:\n",
    "\n",
    "1. A voice cloning (VC) system that clones a given speaker's spoken audio to the target speaker's voice.\n",
    "2. A fake audio detection (FAD) system that detects if any spoken audio is natural speech or synthetically generated by machines.\n",
    "\n",
    "More details can be found in <a href=\"https://github.com/henryhyunwookim/K7h2vHrgG1Gl0S2r#readme\">README</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>1. Import functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "# https://tts.readthedocs.io/en/latest/inference.html\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2. Load data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path.\n",
    "root_dir = Path(sys.path[0])\n",
    "\n",
    "timit_dir = root_dir / 'data' / 'TIMIT' / 'archive'\n",
    "common_voice_dir = root_dir / 'data' / 'CommonVoice' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23-en.tar' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23-en' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23' / 'en' / 'clips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI681.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_or_train dialect_region speaker_id       filename  \\\n",
       "index                                                          \n",
       "1             TRAIN            DR4      MMDM0  SI681.WAV.wav   \n",
       "2             TRAIN            DR4      MMDM0     SI1311.PHN   \n",
       "3             TRAIN            DR4      MMDM0     SI1311.WRD   \n",
       "4             TRAIN            DR4      MMDM0      SX321.PHN   \n",
       "5             TRAIN            DR4      MMDM0      SX321.WRD   \n",
       "\n",
       "                  path_from_data_dir        path_from_data_dir_windows  \\\n",
       "index                                                                    \n",
       "1      TRAIN/DR4/MMDM0/SI681.WAV.wav  TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav   \n",
       "2         TRAIN/DR4/MMDM0/SI1311.PHN     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN   \n",
       "3         TRAIN/DR4/MMDM0/SI1311.WRD     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD   \n",
       "4          TRAIN/DR4/MMDM0/SX321.PHN      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN   \n",
       "5          TRAIN/DR4/MMDM0/SX321.WRD      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD   \n",
       "\n",
       "      is_converted_audio is_audio is_word_file is_phonetic_file  \\\n",
       "index                                                             \n",
       "1                   True     True        False            False   \n",
       "2                  False    False        False             True   \n",
       "3                  False    False         True            False   \n",
       "4                  False    False        False             True   \n",
       "5                  False    False         True            False   \n",
       "\n",
       "      is_sentence_file  \n",
       "index                   \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  \n",
       "5                False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(timit_dir / 'train_data.csv', index_col='index').dropna(how='all')\n",
    "train_csv.index = train_csv.index.astype(int).astype(str)\n",
    "\n",
    "test_csv = pd.read_csv(timit_dir / 'test_data.csv', index_col='index').dropna(how='any')\n",
    "test_csv.index = test_csv.index.astype(int).astype(str)\n",
    "\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path: d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\data\\TIMIT\\archive\\data\\TRAIN\\DR4\\MMDM0\\SI681.WAV.wav\n",
      "Target path: d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\data\\TIMIT\\archive\\data\\TRAIN\\DR8\\MRDM0\\SA2.WAV.wav\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('d:/OneDrive/GitHub/Apziva/K7h2vHrgG1Gl0S2r/output/SI681_to_SA2/SI681_to_SA2.wav')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_audio_path = train_csv[train_csv['is_converted_audio']==True]['path_from_data_dir']\n",
    "\n",
    "source_audio_subpath = train_audio_path[0]\n",
    "source_audio_file = source_audio_subpath.split('/')[3]\n",
    "source_speaker_id = source_audio_file.split('.')[0]\n",
    "source_audio_path = timit_dir / 'data' / source_audio_subpath\n",
    "print(f'Source path: {source_audio_path}')\n",
    "\n",
    "target_audio_subpath = train_audio_path[-1]\n",
    "target_audio_file = target_audio_subpath.split('/')[3]\n",
    "target_speaker_id = target_audio_file.split('.')[0]\n",
    "target_audio_path = timit_dir / 'data' / target_audio_subpath\n",
    "print(f'Target path: {target_audio_path}')\n",
    "\n",
    "output_folder = root_dir / 'output' / f'{source_speaker_id}_to_{target_speaker_id}'\n",
    "output_path = output_folder / f'{source_speaker_id}_to_{target_speaker_id}.wav'\n",
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI681.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_or_train dialect_region speaker_id       filename  \\\n",
       "index                                                          \n",
       "1             TRAIN            DR4      MMDM0  SI681.WAV.wav   \n",
       "2             TRAIN            DR4      MMDM0     SI1311.PHN   \n",
       "3             TRAIN            DR4      MMDM0     SI1311.WRD   \n",
       "4             TRAIN            DR4      MMDM0      SX321.PHN   \n",
       "5             TRAIN            DR4      MMDM0      SX321.WRD   \n",
       "\n",
       "                  path_from_data_dir        path_from_data_dir_windows  \\\n",
       "index                                                                    \n",
       "1      TRAIN/DR4/MMDM0/SI681.WAV.wav  TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav   \n",
       "2         TRAIN/DR4/MMDM0/SI1311.PHN     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN   \n",
       "3         TRAIN/DR4/MMDM0/SI1311.WRD     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD   \n",
       "4          TRAIN/DR4/MMDM0/SX321.PHN      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN   \n",
       "5          TRAIN/DR4/MMDM0/SX321.WRD      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD   \n",
       "\n",
       "      is_converted_audio is_audio is_word_file is_phonetic_file  \\\n",
       "index                                                             \n",
       "1                   True     True        False            False   \n",
       "2                  False    False        False             True   \n",
       "3                  False    False         True            False   \n",
       "4                  False    False        False             True   \n",
       "5                  False    False         True            False   \n",
       "\n",
       "      is_sentence_file  \n",
       "index                   \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  \n",
       "5                False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(timit_dir / 'train_data.csv', index_col='index').dropna(how='all')\n",
    "train_csv.index = train_csv.index.astype(int).astype(str)\n",
    "\n",
    "test_csv = pd.read_csv(timit_dir / 'test_data.csv', index_col='index').dropna(how='any')\n",
    "test_csv.index = test_csv.index.astype(int).astype(str)\n",
    "\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. clone audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy original source and target files to the destination folder\n",
    "# for an easier review of the output file.\n",
    "\n",
    "from shutil import copy2\n",
    "import os\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "# Copy with file permission and dest can be a folder\n",
    "if not os.path.exists(output_folder / source_audio_file):\n",
    "    copy2(src=source_audio_path, dst=output_folder / source_audio_file)\n",
    "if not os.path.exists(output_folder / target_audio_file):\n",
    "    copy2(src=target_audio_path, dst=output_folder / target_audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.09 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('d:/OneDrive/GitHub/Apziva/K7h2vHrgG1Gl0S2r/output/SI681_to_SA2/SI681_to_SA2.wav')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example voice conversion converting speaker of the source_wav to the speaker of the target_wav\n",
    "# Downloading model to C:\\Users\\Admin\\AppData\\Local\\tts\\voice_conversion_models--multilingual--vctk--freevc24\n",
    "tts = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False, gpu=False)\n",
    "tts.voice_conversion_to_file(\n",
    "    source_wav=str(source_audio_path),\n",
    "    target_wav=str(target_audio_path),\n",
    "    file_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-1. speech to text using the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.google.com/search?q=python+speech+to+text+audio+file&oq=python+speech+to+text+audio+file&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRhA0gEIOTAyM2owajeoAgCwAgA&sourceid=chrome&ie=UTF-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pick up one or two files for EDA since typically audio files are very heavy. do not pick up more than 5 files at a time, which might not be even possible.\n",
    "\n",
    "- Can try these to deal with the volume and high dimensionality of audio data:\n",
    "1) Google Colab\n",
    "2) Keras Audio data loading\n",
    "https://keras.io/api/data_loading/audio/#audio_dataset_from_directory-function\n",
    "\n",
    "\n",
    "- will need a library that converts audio files to machine-readable data, i.e. numbers.\n",
    "- will need another library that trains a model (e.g. sequence/ deep learning model for time series audio data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
