{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "### <b>Table of Content</b>\n",
    "\n",
    "0. Background\n",
    "\n",
    "1. Import functions\n",
    "\n",
    "2. Load data\n",
    "\n",
    "3. Explore data<br>\n",
    "    3-1. Examine and transform data formats<br>\n",
    "    3-2. Plot histograms and box plots<br>\n",
    "    3-3. Plot a correlation heatmap<br>\n",
    "    3-4. Plot seasonal decomposition<br>\n",
    "    3-5. Plot autocorrelations\n",
    "\n",
    "3. build a classification model to access the performance of cloned audio's target speaker\n",
    "    3-1. Convert .wav to machine-readable form\n",
    "    3-2. train a model\n",
    "    3-3. evaluate classification accuracy using test data\n",
    "\n",
    "4. first, build a voice cloning system given a speaker’s spoken audio that clones the source speaker’s voice to the target speaker’s voice<br>\n",
    "    4-1. For the voice cloning system (VC), you can utilize the TIMIT dataset as it consists of aligned text-audio data with various speakers.<br>\n",
    "    4-2. Use Word Error Rate (WER) for automatic evaluation of the voice cloning (VC) system for the speech generation part<br>\n",
    "    &emsp; 4-2-1. speech to text<br>\n",
    "    &emsp; 4-2-2. measure WER using the original script and transcribed text<br>\n",
    "    4-3. also report speaker classification accuracy to assess the performance of the generated audio’s target speaker.\n",
    "\n",
    "5. Next, build a machine learning system which detects if any spoken audio is a natural speech or synthetically generated by machine.<br>\n",
    "    5-1. For the fake audio detection system (FAD) you can utilize the CommonVoice dataset as it consists of thousands of naturally spoken audio which could be used as golden spoken audio by humans as positive examples and creating negative examples using the voice cloning system as automatic data/label generator.<br>\n",
    "    5-2. For the fake audio detection (FAD) system evaluate the performance of the models using F-score via positive labels coming from the groundtruth dataset and negative labels generated by the VC.\n",
    "\n",
    "\n",
    "\n",
    "4. Select and engineer features\n",
    "\n",
    "5. Train models<br>\n",
    "    5-1. Split data into train and test sets<br>\n",
    "    5-2. SARIMAX model<br>\n",
    "    &emsp; 5-2-1. Perform stepwise search<br>\n",
    "    &emsp; 5-2-2. Train with best orders<br>\n",
    "    5-3. Train and evaluate different models<br>\n",
    "    &emsp; 5-3-1. Train three different models<br>\n",
    "    &emsp; 5-3-2. Compare model performance\n",
    "\n",
    "6. Evaluate prediction results<br>\n",
    "    6-1. Create Bollinger Bands<br>\n",
    "    6-2. Get trading dates with different intervals<br>\n",
    "    6-3. Make training decisions and get capital returns<br>\n",
    "    &emsp; 6-3-1. Based on SARIMAX predictions<br>\n",
    "    &emsp; 6-3-2. Based on Bollinger Band\n",
    "\n",
    "7. Build pipeline and process all stock data<br>\n",
    "    7-1. Interpret results<br>\n",
    "    &emsp; 7-1-1. Capital returns<br>\n",
    "    &emsp; 7-1-2. Model performance\n",
    "\n",
    "8. Conclusion\n",
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>0. Background</b>\n",
    "\n",
    "This project is for a cyber security company providing products and services that can detect whether audio and video media is authentic or fake.\n",
    "\n",
    "We are given two publically available corpora of speech data, which are the <a href=\"https://github.com/philipperemy/timit\">TIMIT</a> and <a href=\"https://commonvoice.mozilla.org/en/datasets\">CommonVoice</a> datasets. We will build two machine learning systems using these datasets as follows:\n",
    "\n",
    "1. A voice cloning (VC) system that clones a given speaker's spoken audio to the target speaker's voice.\n",
    "2. A fake audio detection (FAD) system that detects if any spoken audio is natural speech or synthetically generated by machines.\n",
    "\n",
    "More details can be found in <a href=\"https://github.com/henryhyunwookim/K7h2vHrgG1Gl0S2r#readme\">README</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>1. Import functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "# https://tts.readthedocs.io/en/latest/inference.html\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2. Load data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path.\n",
    "root_dir = Path(sys.path[0])\n",
    "\n",
    "timit_dir = root_dir / 'data' / 'TIMIT' / 'archive'\n",
    "common_voice_dir = root_dir / 'data' / 'CommonVoice' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23-en.tar' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23-en' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23' / 'en' / 'clips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI681.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_or_train dialect_region speaker_id       filename  \\\n",
       "0         TRAIN            DR4      MMDM0  SI681.WAV.wav   \n",
       "1         TRAIN            DR4      MMDM0     SI1311.PHN   \n",
       "2         TRAIN            DR4      MMDM0     SI1311.WRD   \n",
       "3         TRAIN            DR4      MMDM0      SX321.PHN   \n",
       "4         TRAIN            DR4      MMDM0      SX321.WRD   \n",
       "\n",
       "              path_from_data_dir        path_from_data_dir_windows  \\\n",
       "0  TRAIN/DR4/MMDM0/SI681.WAV.wav  TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav   \n",
       "1     TRAIN/DR4/MMDM0/SI1311.PHN     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN   \n",
       "2     TRAIN/DR4/MMDM0/SI1311.WRD     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD   \n",
       "3      TRAIN/DR4/MMDM0/SX321.PHN      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN   \n",
       "4      TRAIN/DR4/MMDM0/SX321.WRD      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD   \n",
       "\n",
       "  is_converted_audio is_audio is_word_file is_phonetic_file is_sentence_file  \n",
       "0               True     True        False            False            False  \n",
       "1              False    False        False             True            False  \n",
       "2              False    False         True            False            False  \n",
       "3              False    False        False             True            False  \n",
       "4              False    False         True            False            False  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(timit_dir / 'train_data.csv', index_col='index').dropna(how='all').reset_index(drop=True)\n",
    "train_csv.index = train_csv.index.astype(int).astype(str)\n",
    "\n",
    "test_csv = pd.read_csv(timit_dir / 'test_data.csv', index_col='index').dropna(how='any').reset_index(drop=True)\n",
    "test_csv.index = test_csv.index.astype(int).astype(str)\n",
    "\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path: d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\data\\TIMIT\\archive\\data\\TRAIN\\DR4\\MMDM0\\SI681.WAV.wav\n",
      "Target path: d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\data\\TIMIT\\archive\\data\\TRAIN\\DR8\\MRDM0\\SA2.WAV.wav\n"
     ]
    }
   ],
   "source": [
    "train_audio_path = train_csv[train_csv['is_converted_audio']==True]['path_from_data_dir']\n",
    "test_audio_path = test_csv[test_csv['is_converted_audio']==True]['path_from_data_dir']\n",
    "\n",
    "source_audio_subpath = train_audio_path[0]\n",
    "source_speaker_id = source_audio_subpath.split('/')[2]\n",
    "source_audio_file = source_audio_subpath.split('/')[3]\n",
    "source_file_id = source_audio_file.split('.')[0]\n",
    "source_audio_path = timit_dir / 'data' / source_audio_subpath\n",
    "\n",
    "import string\n",
    "source_text_subpath = train_csv[(train_csv['speaker_id']==source_speaker_id) &\n",
    "          (train_csv['filename']==source_file_id+'.TXT')]['path_from_data_dir'][0]\n",
    "source_text_file = source_text_subpath.split('/')[3]\n",
    "source_text_path = timit_dir / 'data' / source_text_subpath\n",
    "with open(source_text_path) as txt:\n",
    "    raw_source_text = txt.read().split()[2:]\n",
    "source_text = ' '.join(raw_source_text) # Remove whitespace\n",
    "source_text = source_text.translate(str.maketrans('', '', string.punctuation)) # Remove punctuation\n",
    "source_text = source_text.lower() # Convert to lowercase\n",
    "print(f'Source path: {source_audio_path}')\n",
    "\n",
    "target_audio_subpath = train_audio_path[-1]\n",
    "target_speaker_id = target_audio_subpath.split('/')[2]\n",
    "target_audio_file = target_audio_subpath.split('/')[3]\n",
    "target_file_id = target_audio_file.split('.')[0]\n",
    "target_audio_path = timit_dir / 'data' / target_audio_subpath\n",
    "print(f'Target path: {target_audio_path}')\n",
    "\n",
    "output_folder = root_dir / 'output' / f'{source_speaker_id}-{source_file_id}_to_{target_speaker_id}-{target_file_id}'\n",
    "output_filename = f'{source_speaker_id}-{source_file_id}_to_{target_speaker_id}-{target_file_id}.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. clone audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy original source and target files to the destination folder\n",
    "# for an easier review of the output file.\n",
    "from shutil import copy2\n",
    "import os\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "# Copy with file permission and dest can be a folder\n",
    "if not os.path.exists(output_folder / source_audio_file):\n",
    "    copy2(src=source_audio_path, dst=output_folder / source_audio_file)\n",
    "if not os.path.exists(output_folder / target_audio_file):\n",
    "    copy2(src=target_audio_path, dst=output_folder / target_audio_file)\n",
    "if not os.path.exists(output_folder / source_text_file):\n",
    "    copy2(src=source_text_path, dst=output_folder / source_text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\multi_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n"
     ]
    }
   ],
   "source": [
    "# Example voice conversion converting speaker of the source_wav to the speaker of the target_wav\n",
    "# Downloading model to C:\\Users\\Admin\\AppData\\Local\\tts\\voice_conversion_models--multilingual--vctk--freevc24   \n",
    "multi_output_path = output_folder / f'multi_{output_filename}'\n",
    "if os.path.exists(multi_output_path):\n",
    "    print(f'{multi_output_path} already exists.')\n",
    "else:\n",
    "    multi_tts = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False, gpu=False)\n",
    "    multi_tts.voice_conversion_to_file(\n",
    "        source_wav=str(source_audio_path),\n",
    "        target_wav=str(target_audio_path),\n",
    "        file_path=multi_output_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for 🐸Coqui Studio voices - https://coqui.ai \n",
      "Visit 🔗https://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\tacotron2_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\tacotron2-DDC_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\tacotron2-DDC_ph_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\glow-tts_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\speedy-speech_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\tacotron2-DCA_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\vits_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\vits--neon_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\fast_pitch_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\overflow_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\neural_hmm_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\vits_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\fast_pitch_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\tacotron-DDC_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\capacitron-t2-c50_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\capacitron-t2-c150_v2_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      " > tts_models/en/multi-dataset/tortoise-v2 is already downloaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [!] Config for tortoise cannot be found.\n",
      "Failed to load tortoise-v2.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\jenny_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n"
     ]
    }
   ],
   "source": [
    "# TTS with on the fly voice conversion\n",
    "en_models = [model for model in TTS.list_models() if '/en/' in model]\n",
    "for model in en_models:\n",
    "    try:\n",
    "        model_name = model.split('/')[-1]\n",
    "        output_file_path = output_folder / f'{model_name}_{output_filename}'\n",
    "        if os.path.exists(output_file_path):\n",
    "            print(f'{output_file_path} already exists.')\n",
    "        else:\n",
    "            en_tts = TTS(model)\n",
    "            en_tts.tts_with_vc_to_file(\n",
    "                source_text,\n",
    "                speaker_wav=str(target_audio_path),\n",
    "                file_path=output_file_path\n",
    "            )\n",
    "    except Exception  as e:\n",
    "        print(e)\n",
    "        print(f'Failed to load {model_name}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>evaluate results in D:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-1. speech to text using the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: what's such an act of refuse to be used for\n",
      "Performance of model \"capacitron-t2-c150\":\n",
      "sentence 1\n",
      "REF:  would such an act of ****** refusal be **** useful\n",
      "HYP: what's such an act of refuse      to be used    for\n",
      "          S                     I       S       I      S\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=3 deletions=0 insertions=2 hits=5\n",
      "\n",
      "mer=50.00%\n",
      "wil=68.75%\n",
      "wip=31.25%\n",
      "wer=62.50%\n",
      "\n",
      "sentence 1\n",
      "REF: w*ould such an act of refus**al be use**ful\n",
      "HYP: what's such an act of refuse to be used for\n",
      "      ISSSS                     IISS       II SS\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=8 deletions=0 insertions=5 hits=30\n",
      "\n",
      "cer=34.21%\n",
      "\n",
      "\n",
      "Transcription: what's such an act of refusal be useful\n",
      "Performance of model \"capacitron-t2-c50\":\n",
      "sentence 1\n",
      "REF:  would such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "          S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: w*ould such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "      ISSSS                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=4 deletions=0 insertions=1 hits=34\n",
      "\n",
      "cer=13.16%\n",
      "\n",
      "\n",
      "Transcription: I would such an act of refusal be useful in\n",
      "Performance of model \"fast\":\n",
      "sentence 1\n",
      "REF: * would such an act of refusal be useful **\n",
      "HYP: I would such an act of refusal be useful in\n",
      "     I                                         I\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=2 hits=8\n",
      "\n",
      "mer=20.00%\n",
      "wil=20.00%\n",
      "wip=80.00%\n",
      "wer=25.00%\n",
      "\n",
      "sentence 1\n",
      "REF: **would such an act of refusal be useful***\n",
      "HYP: I would such an act of refusal be useful in\n",
      "     II                                      III\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=5 hits=38\n",
      "\n",
      "cer=13.16%\n",
      "\n",
      "\n",
      "Transcription: was such an act of refusal be useful\n",
      "Performance of model \"glow-tts\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP:   was such an act of refusal be useful\n",
      "         S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: was** such an act of refusal be useful\n",
      "      SSDD                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=2 deletions=2 insertions=0 hits=34\n",
      "\n",
      "cer=10.53%\n",
      "\n",
      "\n",
      "Transcription: was such an act of refusal be useful\n",
      "Performance of model \"jenny\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP:   was such an act of refusal be useful\n",
      "         S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: was** such an act of refusal be useful\n",
      "      SSDD                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=2 deletions=2 insertions=0 hits=34\n",
      "\n",
      "cer=10.53%\n",
      "\n",
      "\n",
      "Transcription: with such an act of refusal be used\n",
      "Performance of model \"multi\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP:  with such an act of refusal be   used\n",
      "         S                                S\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=2 deletions=0 insertions=0 hits=6\n",
      "\n",
      "mer=25.00%\n",
      "wil=43.75%\n",
      "wip=56.25%\n",
      "wer=25.00%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: with* such an act of refusal be used**\n",
      "      SSSD                              SDD\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=4 deletions=3 insertions=0 hits=31\n",
      "\n",
      "cer=18.42%\n",
      "\n",
      "\n",
      "Transcription: would such an act of refusal be useful\n",
      "Performance of model \"neural\":\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=8\n",
      "\n",
      "mer=0.00%\n",
      "wil=0.00%\n",
      "wip=100.00%\n",
      "wer=0.00%\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=38\n",
      "\n",
      "cer=0.00%\n",
      "\n",
      "\n",
      "Transcription: would such an act of refusal be useful\n",
      "Performance of model \"overflow\":\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=8\n",
      "\n",
      "mer=0.00%\n",
      "wil=0.00%\n",
      "wip=100.00%\n",
      "wer=0.00%\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=38\n",
      "\n",
      "cer=0.00%\n",
      "\n",
      "\n",
      "Transcription: would such an act of refusal be used to\n",
      "Performance of model \"speedy-speech\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be **** useful\n",
      "HYP: would such an act of refusal be used     to\n",
      "                                        I      S\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=1 hits=7\n",
      "\n",
      "mer=22.22%\n",
      "wil=31.94%\n",
      "wip=68.06%\n",
      "wer=25.00%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be use*ful\n",
      "HYP: would such an act of refusal be used to\n",
      "                                        ISSS\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=3 deletions=0 insertions=1 hits=35\n",
      "\n",
      "cer=10.53%\n",
      "\n",
      "\n",
      "Transcription: Wasatch an act of refusal be useful\n",
      "Performance of model \"tacotron-DDC\":\n",
      "sentence 1\n",
      "REF:   would such an act of refusal be useful\n",
      "HYP: Wasatch **** an act of refusal be useful\n",
      "           S    D                            \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=1 insertions=0 hits=6\n",
      "\n",
      "mer=25.00%\n",
      "wil=35.71%\n",
      "wip=64.29%\n",
      "wer=25.00%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: Wasat***ch an act of refusal be useful\n",
      "     SSSSSDDD                              \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=5 deletions=3 insertions=0 hits=30\n",
      "\n",
      "cer=21.05%\n",
      "\n",
      "\n",
      "Transcription: would such an active refusal be useful\n",
      "Performance of model \"tacotron2-DCA\":\n",
      "sentence 1\n",
      "REF: would such an    act of refusal be useful\n",
      "HYP: would such an active ** refusal be useful\n",
      "                        S  D                  \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=1 insertions=0 hits=6\n",
      "\n",
      "mer=25.00%\n",
      "wil=35.71%\n",
      "wip=64.29%\n",
      "wer=25.00%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: would such an active refusal be useful\n",
      "                      SSS                  \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=3 deletions=0 insertions=0 hits=35\n",
      "\n",
      "cer=7.89%\n",
      "\n",
      "\n",
      "Transcription: would such an act of refusal be useful\n",
      "Performance of model \"tacotron2-DDC\":\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=8\n",
      "\n",
      "mer=0.00%\n",
      "wil=0.00%\n",
      "wip=100.00%\n",
      "wer=0.00%\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=38\n",
      "\n",
      "cer=0.00%\n",
      "\n",
      "\n",
      "Transcription: what's such an act of refusal be useful\n",
      "Performance of model \"tacotron2-DDC\":\n",
      "sentence 1\n",
      "REF:  would such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "          S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: w*ould such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "      ISSSS                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=4 deletions=0 insertions=1 hits=34\n",
      "\n",
      "cer=13.16%\n",
      "\n",
      "\n",
      "Transcription: with such an act of refusal be useful\n",
      "Performance of model \"tacotron2\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP:  with such an act of refusal be useful\n",
      "         S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: with* such an act of refusal be useful\n",
      "      SSSD                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=3 deletions=1 insertions=0 hits=34\n",
      "\n",
      "cer=10.53%\n",
      "\n",
      "\n",
      "Transcription: put such an act of refusal be useful\n",
      "Performance of model \"vits--neon\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP:   put such an act of refusal be useful\n",
      "         S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: p*ut* such an act of refusal be useful\n",
      "     SD SD                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=2 deletions=2 insertions=0 hits=34\n",
      "\n",
      "cer=10.53%\n",
      "\n",
      "\n",
      "Transcription: what's such an act of refusal be useful\n",
      "Performance of model \"vits\":\n",
      "sentence 1\n",
      "REF:  would such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "          S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: w*ould such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "      ISSSS                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=4 deletions=0 insertions=1 hits=34\n",
      "\n",
      "cer=13.16%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://pdf.co/blog/transcribe-speech-recordings-to-text-python\n",
    "\n",
    "import speech_recognition as sr\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "from jiwer import process_words, process_characters, visualize_alignment\n",
    "\n",
    "eval_dict = {}\n",
    "for filename in os.listdir(output_folder):\n",
    "    if output_filename in filename:\n",
    "        wav_path = output_folder / filename\n",
    "        model_name = filename.split('/')[-1].split('_')[0]\n",
    "        # sound=AudioSegment.from_wav(wav_path)\n",
    "        r=sr.Recognizer()\n",
    "        with sr.AudioFile(str(wav_path)) as source:\n",
    "            audio=r.record(source)\n",
    "            transcription = r.recognize_google(audio, language='en-US')\n",
    "            print(f'Transcription: {transcription}')\n",
    "\n",
    "        eval_dict[model_name] = {}\n",
    "        words_output = process_words(source_text, transcription) # source_text and transcription can be either a string or a list of strings\n",
    "        eval_dict[model_name]['wer'] = words_output.wer\n",
    "        eval_dict[model_name]['mer'] = words_output.mer\n",
    "        eval_dict[model_name]['wil'] = words_output.wil\n",
    "        eval_dict[model_name]['wip'] = words_output.wip\n",
    "\n",
    "        chars_output = process_characters(source_text, transcription)\n",
    "        eval_dict[model_name]['cer'] = chars_output.cer\n",
    "        eval_dict[model_name]['Transcription'] = transcription\n",
    "        \n",
    "        print(f'Performance of model \"{model_name}\":')\n",
    "        print(visualize_alignment(words_output))\n",
    "        print(visualize_alignment(chars_output))\n",
    "        print()\n",
    "\n",
    "        # Saving the Transcript\n",
    "        # transcription_path = output_folder / filename.replace('.wav', '.txt')\n",
    "        # if os.path.exists(transcription_path):\n",
    "        #     print(f'{transcription_path} already exists.')\n",
    "        # else:\n",
    "        #     with open(transcription_path, \"w\") as file:\n",
    "        #         file.write(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source text: would such an act of refusal be useful\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wer</th>\n",
       "      <th>mer</th>\n",
       "      <th>wil</th>\n",
       "      <th>wip</th>\n",
       "      <th>cer</th>\n",
       "      <th>Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neural</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>would such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overflow</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>would such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glow-tts</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>was such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jenny</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>was such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tacotron2</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>with such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vits--neon</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>put such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capacitron-t2-c50</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>what's such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tacotron2-DDC</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>what's such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vits</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>what's such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>I would such an act of refusal be useful in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speedy-speech</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>would such an act of refusal be used to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tacotron2-DCA</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>would such an active refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tacotron-DDC</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>Wasatch an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>with such an act of refusal be used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capacitron-t2-c150</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>what's such an act of refuse to be used for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      wer       mer       wil       wip       cer  \\\n",
       "neural                0.0       0.0       0.0       1.0       0.0   \n",
       "overflow              0.0       0.0       0.0       1.0       0.0   \n",
       "glow-tts            0.125     0.125  0.234375  0.765625  0.105263   \n",
       "jenny               0.125     0.125  0.234375  0.765625  0.105263   \n",
       "tacotron2           0.125     0.125  0.234375  0.765625  0.105263   \n",
       "vits--neon          0.125     0.125  0.234375  0.765625  0.105263   \n",
       "capacitron-t2-c50   0.125     0.125  0.234375  0.765625  0.131579   \n",
       "tacotron2-DDC       0.125     0.125  0.234375  0.765625  0.131579   \n",
       "vits                0.125     0.125  0.234375  0.765625  0.131579   \n",
       "fast                 0.25       0.2       0.2       0.8  0.131579   \n",
       "speedy-speech        0.25  0.222222  0.319444  0.680556  0.105263   \n",
       "tacotron2-DCA        0.25      0.25  0.357143  0.642857  0.078947   \n",
       "tacotron-DDC         0.25      0.25  0.357143  0.642857  0.210526   \n",
       "multi                0.25      0.25    0.4375    0.5625  0.184211   \n",
       "capacitron-t2-c150  0.625       0.5    0.6875    0.3125  0.342105   \n",
       "\n",
       "                                                  Transcription  \n",
       "neural                   would such an act of refusal be useful  \n",
       "overflow                 would such an act of refusal be useful  \n",
       "glow-tts                   was such an act of refusal be useful  \n",
       "jenny                      was such an act of refusal be useful  \n",
       "tacotron2                 with such an act of refusal be useful  \n",
       "vits--neon                 put such an act of refusal be useful  \n",
       "capacitron-t2-c50       what's such an act of refusal be useful  \n",
       "tacotron2-DDC           what's such an act of refusal be useful  \n",
       "vits                    what's such an act of refusal be useful  \n",
       "fast                I would such an act of refusal be useful in  \n",
       "speedy-speech           would such an act of refusal be used to  \n",
       "tacotron2-DCA            would such an active refusal be useful  \n",
       "tacotron-DDC                Wasatch an act of refusal be useful  \n",
       "multi                       with such an act of refusal be used  \n",
       "capacitron-t2-c150  what's such an act of refuse to be used for  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Source text: {source_text}')\n",
    "eval_df = pd.DataFrame(eval_dict).T\n",
    "eval_df.sort_values(list(eval_df.columns)[:-1], ascending=[True, True, True, False, True])\n",
    "\n",
    "# The following measures are implemented:\n",
    "# 1. Word Error Rate (WER), which is where this library got its name from. This\n",
    "#   has long been (and arguably still is) the de facto standard for computing\n",
    "#   ASR performance. - the lower the better (i.e. more accurate)\n",
    "# 2. Match Error Rate (MER) - the lower the better (i.e. more accurate)\n",
    "# 3. Word Information Lost (WIL) - the lower the better (i.e. more accurate)\n",
    "# 4. Word Information Preserved (WIP) - the larget the better\n",
    "# 5. Character Error Rate (CER) - the lower the better (i.e. more accurate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build an audio classification model to predict the speaker based on synthesized audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.section.io/engineering-education/machine-learning-for-audio-classification/\n",
    "https://www.analyticsvidhya.com/blog/2022/03/implementing-audio-classification-project-using-deep-learning/\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/audio-classification-with-deep-learning-in-python-cf752b22ba07\n",
    "\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2022/03/implementing-audio-classification-project-using-deep-learning/\n",
    "MFCCs – The MFCC summarizes the frequency distribution across the window size. So, it is possible to analyze both the frequency and time characteristics of the sound. This audio representation will allow us to identify features for classification. So, it will try to convert audio into some kind of features based on time and frequency characteristics that will help us to do classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "source_audio_array, sample_rate = librosa.load(source_audio_path, sr = None)\n",
    "\n",
    "# Play the audio in Jupyter notebook\n",
    "from IPython.display import Audio\n",
    "\n",
    "Audio(data=source_audio_array, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from librosa.display import waveshow\n",
    "plt.figure(figsize=(8, 6))\n",
    "waveshow(source_audio_array, sr=sample_rate);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/4620 [00:00<02:22, 32.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4620/4620 [01:42<00:00, 44.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "    \n",
    "# train_audio_path = train_csv[train_csv['is_converted_audio']==True]['path_from_data_dir']\n",
    "# test_audio_path = test_csv[train_csv['is_converted_audio']==True]['path_from_data_dir']\n",
    "\n",
    "def get_X_and_y(audio_path):\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for audio_subpath in tqdm(audio_path):\n",
    "        audio_path = timit_dir / 'data' / audio_subpath\n",
    "        y = audio_subpath.split('/')[2]\n",
    "        y_list.append(y)\n",
    "\n",
    "        audio_array, sample_rate = librosa.load(audio_path,\n",
    "            sr = None) # Set sr to None to get original sampling rate. Otherwise the default is 22050.\n",
    "        # print(f'Shape of audio array: {audio_array.shape}')\n",
    "\n",
    "        # https://www.analyticsvidhya.com/blog/2022/03/implementing-audio-classification-project-using-deep-learning/\n",
    "        mfccs_features = librosa.feature.mfcc(y=audio_array, sr=sample_rate) # n_mfcc=40\n",
    "        # print(f'Shape of mfccs features: {mfccs_features.shape}')\n",
    "        X = np.mean(mfccs_features.T,axis=0) # Normalize features into the same scale\n",
    "        # print(f'Shape of scaled mfccs features: {X.shape}')\n",
    "        X_list.append(X)\n",
    "\n",
    "    df = pd.DataFrame(X_list)\n",
    "    df['label'] = y_list\n",
    "\n",
    "    X = df.drop(['label'], axis=1)\n",
    "    y = df['label']\n",
    "\n",
    "    return X, y, df\n",
    "\n",
    "train_X, train_y, train_df = get_X_and_y(train_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4620, 20) (4620,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-459.484833</td>\n",
       "      <td>56.761337</td>\n",
       "      <td>-2.669462</td>\n",
       "      <td>19.968649</td>\n",
       "      <td>-23.367184</td>\n",
       "      <td>-3.540117</td>\n",
       "      <td>-14.750872</td>\n",
       "      <td>-10.126809</td>\n",
       "      <td>-2.539186</td>\n",
       "      <td>-9.488992</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.316575</td>\n",
       "      <td>-9.237600</td>\n",
       "      <td>1.366279</td>\n",
       "      <td>-2.545701</td>\n",
       "      <td>-12.262521</td>\n",
       "      <td>3.099277</td>\n",
       "      <td>-2.328727</td>\n",
       "      <td>-6.903233</td>\n",
       "      <td>-0.064869</td>\n",
       "      <td>MMDM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-465.787048</td>\n",
       "      <td>64.562737</td>\n",
       "      <td>-9.489527</td>\n",
       "      <td>8.321322</td>\n",
       "      <td>-21.122004</td>\n",
       "      <td>-2.046137</td>\n",
       "      <td>-21.014496</td>\n",
       "      <td>-7.231303</td>\n",
       "      <td>-7.483816</td>\n",
       "      <td>-4.948157</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.372976</td>\n",
       "      <td>-5.502108</td>\n",
       "      <td>1.284694</td>\n",
       "      <td>-2.473558</td>\n",
       "      <td>-7.687661</td>\n",
       "      <td>1.293272</td>\n",
       "      <td>0.884682</td>\n",
       "      <td>-8.997627</td>\n",
       "      <td>-1.206424</td>\n",
       "      <td>MMDM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-460.641968</td>\n",
       "      <td>63.317535</td>\n",
       "      <td>-2.863496</td>\n",
       "      <td>10.129391</td>\n",
       "      <td>-20.092010</td>\n",
       "      <td>-2.287424</td>\n",
       "      <td>-16.457745</td>\n",
       "      <td>-8.084587</td>\n",
       "      <td>-6.815063</td>\n",
       "      <td>-3.239865</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.894239</td>\n",
       "      <td>-2.476811</td>\n",
       "      <td>2.662166</td>\n",
       "      <td>-1.993033</td>\n",
       "      <td>-7.037549</td>\n",
       "      <td>0.101688</td>\n",
       "      <td>2.700857</td>\n",
       "      <td>-8.354132</td>\n",
       "      <td>-2.119529</td>\n",
       "      <td>MMDM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-472.025757</td>\n",
       "      <td>67.413963</td>\n",
       "      <td>-5.153868</td>\n",
       "      <td>6.219963</td>\n",
       "      <td>-13.424616</td>\n",
       "      <td>-4.105060</td>\n",
       "      <td>-22.515928</td>\n",
       "      <td>-3.277426</td>\n",
       "      <td>-2.497244</td>\n",
       "      <td>-5.639574</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.818600</td>\n",
       "      <td>-5.670763</td>\n",
       "      <td>-0.437742</td>\n",
       "      <td>0.500926</td>\n",
       "      <td>-8.669519</td>\n",
       "      <td>-1.226035</td>\n",
       "      <td>3.584755</td>\n",
       "      <td>-9.111854</td>\n",
       "      <td>-2.529173</td>\n",
       "      <td>MMDM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-471.239319</td>\n",
       "      <td>69.058517</td>\n",
       "      <td>-12.291035</td>\n",
       "      <td>3.194077</td>\n",
       "      <td>-25.257214</td>\n",
       "      <td>-0.998650</td>\n",
       "      <td>-18.970245</td>\n",
       "      <td>-9.737679</td>\n",
       "      <td>-5.135023</td>\n",
       "      <td>-1.857679</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.474608</td>\n",
       "      <td>-6.896949</td>\n",
       "      <td>1.058094</td>\n",
       "      <td>2.615407</td>\n",
       "      <td>-12.128066</td>\n",
       "      <td>0.365896</td>\n",
       "      <td>0.885185</td>\n",
       "      <td>-11.063824</td>\n",
       "      <td>-2.649611</td>\n",
       "      <td>MMDM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>-423.451477</td>\n",
       "      <td>95.278877</td>\n",
       "      <td>-22.301649</td>\n",
       "      <td>3.708834</td>\n",
       "      <td>-18.656015</td>\n",
       "      <td>-12.609299</td>\n",
       "      <td>-12.033003</td>\n",
       "      <td>-10.555429</td>\n",
       "      <td>-2.433274</td>\n",
       "      <td>-6.521004</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.722636</td>\n",
       "      <td>-8.361225</td>\n",
       "      <td>-2.762403</td>\n",
       "      <td>-3.371542</td>\n",
       "      <td>-7.972284</td>\n",
       "      <td>-2.850656</td>\n",
       "      <td>-1.245145</td>\n",
       "      <td>-5.436496</td>\n",
       "      <td>-6.501590</td>\n",
       "      <td>MRDM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4616</th>\n",
       "      <td>-386.019409</td>\n",
       "      <td>87.441643</td>\n",
       "      <td>-20.666483</td>\n",
       "      <td>-1.609706</td>\n",
       "      <td>-24.377481</td>\n",
       "      <td>-11.676523</td>\n",
       "      <td>-17.594046</td>\n",
       "      <td>-17.587301</td>\n",
       "      <td>-3.453123</td>\n",
       "      <td>-6.572145</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.804390</td>\n",
       "      <td>-12.402589</td>\n",
       "      <td>4.166420</td>\n",
       "      <td>-3.674955</td>\n",
       "      <td>-10.928297</td>\n",
       "      <td>1.093287</td>\n",
       "      <td>-4.062526</td>\n",
       "      <td>-6.624683</td>\n",
       "      <td>-5.267781</td>\n",
       "      <td>MRDM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>-400.804199</td>\n",
       "      <td>98.299683</td>\n",
       "      <td>-32.088337</td>\n",
       "      <td>-1.725039</td>\n",
       "      <td>-20.465277</td>\n",
       "      <td>-11.593572</td>\n",
       "      <td>-22.799036</td>\n",
       "      <td>-14.846024</td>\n",
       "      <td>-1.932206</td>\n",
       "      <td>-13.435257</td>\n",
       "      <td>...</td>\n",
       "      <td>2.143220</td>\n",
       "      <td>-13.219035</td>\n",
       "      <td>-1.477908</td>\n",
       "      <td>-4.940297</td>\n",
       "      <td>-6.138267</td>\n",
       "      <td>-1.202820</td>\n",
       "      <td>-4.640791</td>\n",
       "      <td>-4.390095</td>\n",
       "      <td>-5.367548</td>\n",
       "      <td>MRDM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>-416.451416</td>\n",
       "      <td>65.583344</td>\n",
       "      <td>-7.596760</td>\n",
       "      <td>6.540810</td>\n",
       "      <td>-20.395090</td>\n",
       "      <td>-9.472665</td>\n",
       "      <td>-15.429052</td>\n",
       "      <td>-12.100680</td>\n",
       "      <td>-4.556737</td>\n",
       "      <td>-5.017276</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.022671</td>\n",
       "      <td>-11.940890</td>\n",
       "      <td>4.366385</td>\n",
       "      <td>-7.756617</td>\n",
       "      <td>-7.010954</td>\n",
       "      <td>1.492949</td>\n",
       "      <td>-5.822121</td>\n",
       "      <td>-4.933115</td>\n",
       "      <td>-3.898118</td>\n",
       "      <td>MRDM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>-383.452209</td>\n",
       "      <td>106.107697</td>\n",
       "      <td>-46.611538</td>\n",
       "      <td>7.122592</td>\n",
       "      <td>-20.040308</td>\n",
       "      <td>-13.433887</td>\n",
       "      <td>-22.046066</td>\n",
       "      <td>-15.962587</td>\n",
       "      <td>-2.001069</td>\n",
       "      <td>-6.701435</td>\n",
       "      <td>...</td>\n",
       "      <td>2.198071</td>\n",
       "      <td>-11.834779</td>\n",
       "      <td>2.863689</td>\n",
       "      <td>-3.951947</td>\n",
       "      <td>-10.634558</td>\n",
       "      <td>0.175627</td>\n",
       "      <td>-10.438201</td>\n",
       "      <td>-1.546928</td>\n",
       "      <td>-9.429408</td>\n",
       "      <td>MRDM0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4620 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1          2          3          4          5  \\\n",
       "0    -459.484833   56.761337  -2.669462  19.968649 -23.367184  -3.540117   \n",
       "1    -465.787048   64.562737  -9.489527   8.321322 -21.122004  -2.046137   \n",
       "2    -460.641968   63.317535  -2.863496  10.129391 -20.092010  -2.287424   \n",
       "3    -472.025757   67.413963  -5.153868   6.219963 -13.424616  -4.105060   \n",
       "4    -471.239319   69.058517 -12.291035   3.194077 -25.257214  -0.998650   \n",
       "...          ...         ...        ...        ...        ...        ...   \n",
       "4615 -423.451477   95.278877 -22.301649   3.708834 -18.656015 -12.609299   \n",
       "4616 -386.019409   87.441643 -20.666483  -1.609706 -24.377481 -11.676523   \n",
       "4617 -400.804199   98.299683 -32.088337  -1.725039 -20.465277 -11.593572   \n",
       "4618 -416.451416   65.583344  -7.596760   6.540810 -20.395090  -9.472665   \n",
       "4619 -383.452209  106.107697 -46.611538   7.122592 -20.040308 -13.433887   \n",
       "\n",
       "              6          7         8          9  ...        11         12  \\\n",
       "0    -14.750872 -10.126809 -2.539186  -9.488992  ... -9.316575  -9.237600   \n",
       "1    -21.014496  -7.231303 -7.483816  -4.948157  ... -8.372976  -5.502108   \n",
       "2    -16.457745  -8.084587 -6.815063  -3.239865  ... -9.894239  -2.476811   \n",
       "3    -22.515928  -3.277426 -2.497244  -5.639574  ... -6.818600  -5.670763   \n",
       "4    -18.970245  -9.737679 -5.135023  -1.857679  ... -4.474608  -6.896949   \n",
       "...         ...        ...       ...        ...  ...       ...        ...   \n",
       "4615 -12.033003 -10.555429 -2.433274  -6.521004  ... -1.722636  -8.361225   \n",
       "4616 -17.594046 -17.587301 -3.453123  -6.572145  ... -2.804390 -12.402589   \n",
       "4617 -22.799036 -14.846024 -1.932206 -13.435257  ...  2.143220 -13.219035   \n",
       "4618 -15.429052 -12.100680 -4.556737  -5.017276  ... -2.022671 -11.940890   \n",
       "4619 -22.046066 -15.962587 -2.001069  -6.701435  ...  2.198071 -11.834779   \n",
       "\n",
       "            13        14         15        16         17         18        19  \\\n",
       "0     1.366279 -2.545701 -12.262521  3.099277  -2.328727  -6.903233 -0.064869   \n",
       "1     1.284694 -2.473558  -7.687661  1.293272   0.884682  -8.997627 -1.206424   \n",
       "2     2.662166 -1.993033  -7.037549  0.101688   2.700857  -8.354132 -2.119529   \n",
       "3    -0.437742  0.500926  -8.669519 -1.226035   3.584755  -9.111854 -2.529173   \n",
       "4     1.058094  2.615407 -12.128066  0.365896   0.885185 -11.063824 -2.649611   \n",
       "...        ...       ...        ...       ...        ...        ...       ...   \n",
       "4615 -2.762403 -3.371542  -7.972284 -2.850656  -1.245145  -5.436496 -6.501590   \n",
       "4616  4.166420 -3.674955 -10.928297  1.093287  -4.062526  -6.624683 -5.267781   \n",
       "4617 -1.477908 -4.940297  -6.138267 -1.202820  -4.640791  -4.390095 -5.367548   \n",
       "4618  4.366385 -7.756617  -7.010954  1.492949  -5.822121  -4.933115 -3.898118   \n",
       "4619  2.863689 -3.951947 -10.634558  0.175627 -10.438201  -1.546928 -9.429408   \n",
       "\n",
       "      label  \n",
       "0     MMDM0  \n",
       "1     MMDM0  \n",
       "2     MMDM0  \n",
       "3     MMDM0  \n",
       "4     MMDM0  \n",
       "...     ...  \n",
       "4615  MRDM0  \n",
       "4616  MRDM0  \n",
       "4617  MRDM0  \n",
       "4618  MRDM0  \n",
       "4619  MRDM0  \n",
       "\n",
       "[4620 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_X.shape, train_y.shape)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1680/1680 [01:15<00:00, 22.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1680, 20) (1680,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-416.969818</td>\n",
       "      <td>74.011398</td>\n",
       "      <td>-13.187699</td>\n",
       "      <td>7.313196</td>\n",
       "      <td>-16.026976</td>\n",
       "      <td>-8.255945</td>\n",
       "      <td>-15.144563</td>\n",
       "      <td>-12.874265</td>\n",
       "      <td>-12.429185</td>\n",
       "      <td>-11.921021</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.728844</td>\n",
       "      <td>-7.919119</td>\n",
       "      <td>0.885161</td>\n",
       "      <td>-2.531504</td>\n",
       "      <td>-3.715901</td>\n",
       "      <td>2.588741</td>\n",
       "      <td>-3.963770</td>\n",
       "      <td>-4.285760</td>\n",
       "      <td>-3.759105</td>\n",
       "      <td>MGMM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-403.078735</td>\n",
       "      <td>76.966255</td>\n",
       "      <td>-18.775089</td>\n",
       "      <td>-1.268906</td>\n",
       "      <td>-9.745815</td>\n",
       "      <td>-5.179509</td>\n",
       "      <td>-23.778231</td>\n",
       "      <td>-17.591146</td>\n",
       "      <td>-6.624335</td>\n",
       "      <td>-11.397276</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.800530</td>\n",
       "      <td>-7.827424</td>\n",
       "      <td>4.408467</td>\n",
       "      <td>-3.831102</td>\n",
       "      <td>-5.387887</td>\n",
       "      <td>0.043134</td>\n",
       "      <td>-2.391682</td>\n",
       "      <td>-3.166301</td>\n",
       "      <td>-6.031714</td>\n",
       "      <td>MGMM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-467.837006</td>\n",
       "      <td>75.185669</td>\n",
       "      <td>-21.702417</td>\n",
       "      <td>3.530928</td>\n",
       "      <td>-7.479931</td>\n",
       "      <td>-10.674512</td>\n",
       "      <td>-20.365223</td>\n",
       "      <td>-11.112667</td>\n",
       "      <td>-5.670715</td>\n",
       "      <td>-9.603108</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.326303</td>\n",
       "      <td>-5.674239</td>\n",
       "      <td>-0.227867</td>\n",
       "      <td>0.024477</td>\n",
       "      <td>-5.983346</td>\n",
       "      <td>-0.001973</td>\n",
       "      <td>-4.833220</td>\n",
       "      <td>-2.994748</td>\n",
       "      <td>-3.716501</td>\n",
       "      <td>MGMM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-418.118164</td>\n",
       "      <td>37.631710</td>\n",
       "      <td>-8.191947</td>\n",
       "      <td>14.002369</td>\n",
       "      <td>-6.737182</td>\n",
       "      <td>-5.914884</td>\n",
       "      <td>-20.806435</td>\n",
       "      <td>-8.180764</td>\n",
       "      <td>-2.208747</td>\n",
       "      <td>-10.896692</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.398853</td>\n",
       "      <td>-5.102459</td>\n",
       "      <td>0.283969</td>\n",
       "      <td>-3.945397</td>\n",
       "      <td>-2.221809</td>\n",
       "      <td>-0.478784</td>\n",
       "      <td>-4.513309</td>\n",
       "      <td>-2.042158</td>\n",
       "      <td>-3.401044</td>\n",
       "      <td>MGMM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-435.070526</td>\n",
       "      <td>57.279308</td>\n",
       "      <td>-29.724104</td>\n",
       "      <td>3.099550</td>\n",
       "      <td>-17.637997</td>\n",
       "      <td>-5.830471</td>\n",
       "      <td>-20.228270</td>\n",
       "      <td>-12.256104</td>\n",
       "      <td>-2.303483</td>\n",
       "      <td>-8.506678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906471</td>\n",
       "      <td>-7.174262</td>\n",
       "      <td>3.197781</td>\n",
       "      <td>0.523936</td>\n",
       "      <td>-9.252493</td>\n",
       "      <td>-1.749536</td>\n",
       "      <td>-1.823353</td>\n",
       "      <td>-4.496766</td>\n",
       "      <td>-3.326604</td>\n",
       "      <td>MGMM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>-406.085480</td>\n",
       "      <td>92.109261</td>\n",
       "      <td>-23.479044</td>\n",
       "      <td>-7.624950</td>\n",
       "      <td>-22.940878</td>\n",
       "      <td>-9.834519</td>\n",
       "      <td>-13.621748</td>\n",
       "      <td>-21.213266</td>\n",
       "      <td>-4.604829</td>\n",
       "      <td>-21.231474</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.365309</td>\n",
       "      <td>-12.795815</td>\n",
       "      <td>-2.434451</td>\n",
       "      <td>-5.877679</td>\n",
       "      <td>-7.407432</td>\n",
       "      <td>-3.499592</td>\n",
       "      <td>-2.272517</td>\n",
       "      <td>-0.690597</td>\n",
       "      <td>-9.970720</td>\n",
       "      <td>MPAM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>-385.963654</td>\n",
       "      <td>78.325348</td>\n",
       "      <td>-29.334007</td>\n",
       "      <td>-0.930862</td>\n",
       "      <td>-22.941746</td>\n",
       "      <td>-9.558640</td>\n",
       "      <td>-26.149376</td>\n",
       "      <td>-23.143641</td>\n",
       "      <td>-0.564970</td>\n",
       "      <td>-22.136240</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.822415</td>\n",
       "      <td>-5.651861</td>\n",
       "      <td>-2.994653</td>\n",
       "      <td>-8.926338</td>\n",
       "      <td>-1.621032</td>\n",
       "      <td>-6.353990</td>\n",
       "      <td>-5.315491</td>\n",
       "      <td>-3.241990</td>\n",
       "      <td>-4.528982</td>\n",
       "      <td>MPAM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>-420.404083</td>\n",
       "      <td>56.258163</td>\n",
       "      <td>-10.633552</td>\n",
       "      <td>3.504625</td>\n",
       "      <td>-22.861475</td>\n",
       "      <td>-10.257877</td>\n",
       "      <td>-15.837805</td>\n",
       "      <td>-14.366729</td>\n",
       "      <td>-6.907274</td>\n",
       "      <td>-17.667339</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.835690</td>\n",
       "      <td>-8.947762</td>\n",
       "      <td>-3.208503</td>\n",
       "      <td>-4.989741</td>\n",
       "      <td>-3.821439</td>\n",
       "      <td>-4.549932</td>\n",
       "      <td>-1.142911</td>\n",
       "      <td>-5.954093</td>\n",
       "      <td>-4.140995</td>\n",
       "      <td>MPAM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>-388.224548</td>\n",
       "      <td>83.864449</td>\n",
       "      <td>-20.634623</td>\n",
       "      <td>-10.419191</td>\n",
       "      <td>-26.245213</td>\n",
       "      <td>-7.218798</td>\n",
       "      <td>-23.554562</td>\n",
       "      <td>-19.968264</td>\n",
       "      <td>-8.886330</td>\n",
       "      <td>-16.091333</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.503175</td>\n",
       "      <td>-6.578616</td>\n",
       "      <td>-2.868214</td>\n",
       "      <td>-7.529954</td>\n",
       "      <td>-3.150034</td>\n",
       "      <td>-5.381018</td>\n",
       "      <td>-1.760893</td>\n",
       "      <td>-5.881048</td>\n",
       "      <td>-5.423452</td>\n",
       "      <td>MPAM0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>-361.454987</td>\n",
       "      <td>86.387245</td>\n",
       "      <td>-42.269272</td>\n",
       "      <td>-5.692385</td>\n",
       "      <td>-17.635189</td>\n",
       "      <td>-18.867435</td>\n",
       "      <td>-23.132856</td>\n",
       "      <td>-21.640017</td>\n",
       "      <td>-5.193335</td>\n",
       "      <td>-19.417856</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.807816</td>\n",
       "      <td>-5.034733</td>\n",
       "      <td>-3.532167</td>\n",
       "      <td>-8.198166</td>\n",
       "      <td>-5.678209</td>\n",
       "      <td>-6.966318</td>\n",
       "      <td>-0.787147</td>\n",
       "      <td>-4.362855</td>\n",
       "      <td>-5.952141</td>\n",
       "      <td>MPAM0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1680 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0          1          2          3          4          5  \\\n",
       "0    -416.969818  74.011398 -13.187699   7.313196 -16.026976  -8.255945   \n",
       "1    -403.078735  76.966255 -18.775089  -1.268906  -9.745815  -5.179509   \n",
       "2    -467.837006  75.185669 -21.702417   3.530928  -7.479931 -10.674512   \n",
       "3    -418.118164  37.631710  -8.191947  14.002369  -6.737182  -5.914884   \n",
       "4    -435.070526  57.279308 -29.724104   3.099550 -17.637997  -5.830471   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "1675 -406.085480  92.109261 -23.479044  -7.624950 -22.940878  -9.834519   \n",
       "1676 -385.963654  78.325348 -29.334007  -0.930862 -22.941746  -9.558640   \n",
       "1677 -420.404083  56.258163 -10.633552   3.504625 -22.861475 -10.257877   \n",
       "1678 -388.224548  83.864449 -20.634623 -10.419191 -26.245213  -7.218798   \n",
       "1679 -361.454987  86.387245 -42.269272  -5.692385 -17.635189 -18.867435   \n",
       "\n",
       "              6          7          8          9  ...         11         12  \\\n",
       "0    -15.144563 -12.874265 -12.429185 -11.921021  ...  -2.728844  -7.919119   \n",
       "1    -23.778231 -17.591146  -6.624335 -11.397276  ...  -5.800530  -7.827424   \n",
       "2    -20.365223 -11.112667  -5.670715  -9.603108  ...  -3.326303  -5.674239   \n",
       "3    -20.806435  -8.180764  -2.208747 -10.896692  ...  -3.398853  -5.102459   \n",
       "4    -20.228270 -12.256104  -2.303483  -8.506678  ...   0.906471  -7.174262   \n",
       "...         ...        ...        ...        ...  ...        ...        ...   \n",
       "1675 -13.621748 -21.213266  -4.604829 -21.231474  ...  -9.365309 -12.795815   \n",
       "1676 -26.149376 -23.143641  -0.564970 -22.136240  ... -11.822415  -5.651861   \n",
       "1677 -15.837805 -14.366729  -6.907274 -17.667339  ...  -8.835690  -8.947762   \n",
       "1678 -23.554562 -19.968264  -8.886330 -16.091333  ... -10.503175  -6.578616   \n",
       "1679 -23.132856 -21.640017  -5.193335 -19.417856  ... -11.807816  -5.034733   \n",
       "\n",
       "            13        14        15        16        17        18        19  \\\n",
       "0     0.885161 -2.531504 -3.715901  2.588741 -3.963770 -4.285760 -3.759105   \n",
       "1     4.408467 -3.831102 -5.387887  0.043134 -2.391682 -3.166301 -6.031714   \n",
       "2    -0.227867  0.024477 -5.983346 -0.001973 -4.833220 -2.994748 -3.716501   \n",
       "3     0.283969 -3.945397 -2.221809 -0.478784 -4.513309 -2.042158 -3.401044   \n",
       "4     3.197781  0.523936 -9.252493 -1.749536 -1.823353 -4.496766 -3.326604   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1675 -2.434451 -5.877679 -7.407432 -3.499592 -2.272517 -0.690597 -9.970720   \n",
       "1676 -2.994653 -8.926338 -1.621032 -6.353990 -5.315491 -3.241990 -4.528982   \n",
       "1677 -3.208503 -4.989741 -3.821439 -4.549932 -1.142911 -5.954093 -4.140995   \n",
       "1678 -2.868214 -7.529954 -3.150034 -5.381018 -1.760893 -5.881048 -5.423452   \n",
       "1679 -3.532167 -8.198166 -5.678209 -6.966318 -0.787147 -4.362855 -5.952141   \n",
       "\n",
       "      label  \n",
       "0     MGMM0  \n",
       "1     MGMM0  \n",
       "2     MGMM0  \n",
       "3     MGMM0  \n",
       "4     MGMM0  \n",
       "...     ...  \n",
       "1675  MPAM0  \n",
       "1676  MPAM0  \n",
       "1677  MPAM0  \n",
       "1678  MPAM0  \n",
       "1679  MPAM0  \n",
       "\n",
       "[1680 rows x 21 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_X, test_y, test_df = get_X_and_y(test_audio_path)\n",
    "# print(test_X.shape, test_y.shape)\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MMDM0    10\n",
       "FPAC0    10\n",
       "MKDB0    10\n",
       "MGAW0    10\n",
       "MCLK0    10\n",
       "         ..\n",
       "MEFG0    10\n",
       "MRMS0    10\n",
       "MJHI0    10\n",
       "MRLJ0    10\n",
       "MRDM0    10\n",
       "Name: label, Length: 462, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MGMM0    10\n",
       "FGWR0    10\n",
       "MDWK0    10\n",
       "MLIH0    10\n",
       "FHEW0    10\n",
       "         ..\n",
       "MTDT0    10\n",
       "FSLB1    10\n",
       "MRCZ0    10\n",
       "MTMR0    10\n",
       "MPAM0    10\n",
       "Name: label, Length: 168, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y=to_categorical(labelencoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics\n",
    "\n",
    "model=Sequential()\n",
    "###first layer\n",
    "model.add(Dense(100,input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###second layer\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "###third layer\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "###final layer\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime \n",
    "\n",
    "num_epochs = 200\n",
    "num_batch_size = 32\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpointer], verbose=1)\n",
    "\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(\"Training completed in time: \", duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>predict labels using the cloned audio files in D:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"fold8/103076-3-0-0.wav\"\n",
    "audio, sample_rate = librosa.load(filename, res_type='kaiser_fast') \n",
    "mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "\n",
    "print(mfccs_scaled_features)\n",
    "mfccs_scaled_features=mfccs_scaled_features.reshape(1,-1)\n",
    "print(mfccs_scaled_features)\n",
    "print(mfccs_scaled_features.shape)\n",
    "predicted_label=model.predict(mfccs_scaled_features)\n",
    "print(predicted_label)\n",
    "classes_x=np.argmax(predicted_label,axis=1)\n",
    "prediction_class = labelencoder.inverse_transform(classes_x)\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other VC models:\n",
    "\n",
    "https://paperswithcode.com/task/voice-conversion\n",
    "=>\n",
    "https://github.com/bshall/VectorQuantizedCPC\n",
    "https://github.com/bshall/knn-vc\n",
    "\n",
    "neural network-based voice conversion model, such as CycleGAN, StarGAN-VC, or Tacotron 2\n",
    "\n",
    "VITS\n",
    "\n",
    "VALL-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pick up one or two files for EDA since typically audio files are very heavy. do not pick up more than 5 files at a time, which might not be even possible.\n",
    "\n",
    "- Can try these to deal with the volume and high dimensionality of audio data:\n",
    "1) Google Colab\n",
    "2) Keras Audio data loading\n",
    "https://keras.io/api/data_loading/audio/#audio_dataset_from_directory-function\n",
    "\n",
    "\n",
    "- will need a library that converts audio files to machine-readable data, i.e. numbers.\n",
    "- will need another library that trains a model (e.g. sequence/ deep learning model for time series audio data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
