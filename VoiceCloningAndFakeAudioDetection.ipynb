{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "### <b>Table of Content</b>\n",
    "\n",
    "0. Background\n",
    "\n",
    "1. Import functions\n",
    "\n",
    "2. Load data\n",
    "\n",
    "3. Explore data<br>\n",
    "    3-1. Examine and transform data formats<br>\n",
    "    3-2. Plot histograms and box plots<br>\n",
    "    3-3. Plot a correlation heatmap<br>\n",
    "    3-4. Plot seasonal decomposition<br>\n",
    "    3-5. Plot autocorrelations\n",
    "\n",
    "3. build a classification model to access the performance of cloned audio's target speaker\n",
    "    3-1. Convert .wav to machine-readable form\n",
    "    3-2. train a model\n",
    "    3-3. evaluate classification accuracy using test data\n",
    "\n",
    "4. first, build a voice cloning system given a speaker‚Äôs spoken audio that clones the source speaker‚Äôs voice to the target speaker‚Äôs voice\n",
    "    4-1. For the voice cloning system (VC), you can utilize the TIMIT dataset as it consists of aligned text-audio data with various speakers.\n",
    "    4-2. Use Word Error Rate (WER) for automatic evaluation of the voice cloning (VC) system for the speech generation part\n",
    "    https://medium.com/ibm-watson-speech-services/new-python-scripts-to-measure-word-error-rate-on-watson-speech-to-text-77ecaa513f60\n",
    "    https://github.com/jitsi/jiwer\n",
    "    &emsp; 4-2-1. speech to text\n",
    "    &emsp; 4-2-2. measure WER using the original script and transcribed text\n",
    "    4-3. also report speaker classification accuracy to assess the performance of the generated audio‚Äôs target speaker.\n",
    "\n",
    "5. Next, build a machine learning system which detects if any spoken audio is a natural speech or synthetically generated by machine.\n",
    "    5-1. For the fake audio detection system (FAD) you can utilize the CommonVoice dataset as it consists of thousands of naturally spoken audio which could be used as golden spoken audio by humans as positive examples and creating negative examples using the voice cloning system as automatic data/label generator.\n",
    "    5-2. For the fake audio detection (FAD) system evaluate the performance of the models using F-score via positive labels coming from the groundtruth dataset and negative labels generated by the VC.\n",
    "\n",
    "\n",
    "\n",
    "4. Select and engineer features\n",
    "\n",
    "5. Train models<br>\n",
    "    5-1. Split data into train and test sets<br>\n",
    "    5-2. SARIMAX model<br>\n",
    "    &emsp; 5-2-1. Perform stepwise search<br>\n",
    "    &emsp; 5-2-2. Train with best orders<br>\n",
    "    5-3. Train and evaluate different models<br>\n",
    "    &emsp; 5-3-1. Train three different models<br>\n",
    "    &emsp; 5-3-2. Compare model performance\n",
    "\n",
    "6. Evaluate prediction results<br>\n",
    "    6-1. Create Bollinger Bands<br>\n",
    "    6-2. Get trading dates with different intervals<br>\n",
    "    6-3. Make training decisions and get capital returns<br>\n",
    "    &emsp; 6-3-1. Based on SARIMAX predictions<br>\n",
    "    &emsp; 6-3-2. Based on Bollinger Band\n",
    "\n",
    "7. Build pipeline and process all stock data<br>\n",
    "    7-1. Interpret results<br>\n",
    "    &emsp; 7-1-1. Capital returns<br>\n",
    "    &emsp; 7-1-2. Model performance\n",
    "\n",
    "8. Conclusion\n",
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>0. Background</b>\n",
    "\n",
    "This project is for a cyber security company providing products and services that can detect whether audio and video media is authentic or fake.\n",
    "\n",
    "We are given two publically available corpora of speech data, which are the <a href=\"https://github.com/philipperemy/timit\">TIMIT</a> and <a href=\"https://commonvoice.mozilla.org/en/datasets\">CommonVoice</a> datasets. We will build two machine learning systems using these datasets as follows:\n",
    "\n",
    "1. A voice cloning (VC) system that clones a given speaker's spoken audio to the target speaker's voice.\n",
    "2. A fake audio detection (FAD) system that detects if any spoken audio is natural speech or synthetically generated by machines.\n",
    "\n",
    "More details can be found in <a href=\"https://github.com/henryhyunwookim/K7h2vHrgG1Gl0S2r#readme\">README</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>1. Import functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "# https://tts.readthedocs.io/en/latest/inference.html\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2. Load data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path.\n",
    "root_dir = Path(sys.path[0])\n",
    "\n",
    "timit_dir = root_dir / 'data' / 'TIMIT' / 'archive'\n",
    "common_voice_dir = root_dir / 'data' / 'CommonVoice' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23-en.tar' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23-en' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23' / 'en' / 'clips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI681.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_or_train dialect_region  ... is_phonetic_file is_sentence_file\n",
       "index                               ...                                  \n",
       "1             TRAIN            DR4  ...            False            False\n",
       "2             TRAIN            DR4  ...             True            False\n",
       "3             TRAIN            DR4  ...            False            False\n",
       "4             TRAIN            DR4  ...             True            False\n",
       "5             TRAIN            DR4  ...            False            False\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(timit_dir / 'train_data.csv', index_col='index').dropna(how='all')\n",
    "train_csv.index = train_csv.index.astype(int).astype(str)\n",
    "\n",
    "test_csv = pd.read_csv(timit_dir / 'test_data.csv', index_col='index').dropna(how='any')\n",
    "test_csv.index = test_csv.index.astype(int).astype(str)\n",
    "\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path: d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\data\\TIMIT\\archive\\data\\TRAIN\\DR4\\MMDM0\\SI681.WAV.wav\n",
      "Target path: d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\data\\TIMIT\\archive\\data\\TRAIN\\DR8\\MRDM0\\SA2.WAV.wav\n"
     ]
    }
   ],
   "source": [
    "train_audio_path = train_csv[train_csv['is_converted_audio']==True]['path_from_data_dir']\n",
    "\n",
    "source_audio_subpath = train_audio_path[0]\n",
    "source_speaker_id = source_audio_subpath.split('/')[2]\n",
    "source_audio_file = source_audio_subpath.split('/')[3]\n",
    "source_file_id = source_audio_file.split('.')[0]\n",
    "source_audio_path = timit_dir / 'data' / source_audio_subpath\n",
    "\n",
    "source_text_subpath = train_csv[(train_csv['speaker_id']==source_speaker_id) &\n",
    "          (train_csv['filename']==source_file_id+'.TXT')]['path_from_data_dir'][0]\n",
    "source_text_path = timit_dir / 'data' / source_text_subpath\n",
    "with open(source_text_path) as txt:\n",
    "    source_text = ' '.join(txt.read().split()[2:])\n",
    "print(f'Source path: {source_audio_path}')\n",
    "\n",
    "target_audio_subpath = train_audio_path[-1]\n",
    "target_speaker_id = target_audio_subpath.split('/')[2]\n",
    "target_audio_file = target_audio_subpath.split('/')[3]\n",
    "target_file_id = target_audio_file.split('.')[0]\n",
    "target_audio_path = timit_dir / 'data' / target_audio_subpath\n",
    "print(f'Target path: {target_audio_path}')\n",
    "\n",
    "output_folder = root_dir / 'output' / f'{source_speaker_id}-{source_file_id}_to_{target_speaker_id}-{target_file_id}'\n",
    "output_filename = f'{source_speaker_id}-{source_file_id}_to_{target_speaker_id}-{target_file_id}.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. clone audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy original source and target files to the destination folder\n",
    "# for an easier review of the output file.\n",
    "\n",
    "from shutil import copy2\n",
    "import os\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "# Copy with file permission and dest can be a folder\n",
    "if not os.path.exists(output_folder / source_audio_file):\n",
    "    copy2(src=source_audio_path, dst=output_folder / source_audio_file)\n",
    "if not os.path.exists(output_folder / target_audio_file):\n",
    "    copy2(src=target_audio_path, dst=output_folder / target_audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.09 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('d:/OneDrive/GitHub/Apziva/K7h2vHrgG1Gl0S2r/output/MMDM0-SI681_to_MRDM0-SA2/multi_MMDM0-SI681_to_MRDM0-SA2.wav')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example voice conversion converting speaker of the source_wav to the speaker of the target_wav\n",
    "# Downloading model to C:\\Users\\Admin\\AppData\\Local\\tts\\voice_conversion_models--multilingual--vctk--freevc24   \n",
    "multi_tts = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False, gpu=False)\n",
    "multi_tts.voice_conversion_to_file(\n",
    "    source_wav=str(source_audio_path),\n",
    "    target_wav=str(target_audio_path),\n",
    "    file_path=output_folder / f'multi_{output_filename}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n",
      " > tts_models/en/ek1/tacotron2 is already downloaded.\n",
      " > vocoder_models/en/ek1/wavegrad is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-10\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.8\n",
      " | > preemphasis:0.99\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: wavegrad\n",
      " > Text splitted to sentences.\n",
      "['Would such an act of refusal be useful?']\n",
      "w äd s åtÕ° É …ôn √¶kt …ôv …π…™fjuz…ôl bi jusf…ôl?\n",
      " [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 216.5360951423645\n",
      " > Real-time factor: 83.6127223642676\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.04 seconds.\n",
      " > tts_models/en/ljspeech/tacotron2-DDC is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 1\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      " > Text splitted to sentences.\n",
      "['Would such an act of refusal be useful?']\n",
      " > Processing time: 2.8934741020202637\n",
      " > Real-time factor: 0.9262645753418527\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.03 seconds.\n",
      " > tts_models/en/ljspeech/tacotron2-DDC_ph is already downloaded.\n",
      " > vocoder_models/en/ljspeech/univnet is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:C:\\Users\\Admin\\AppData\\Local\\tts\\tts_models--en--ljspeech--tacotron2-DDC_ph\\scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: univnet\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:C:\\Users\\Admin\\AppData\\Local\\tts\\vocoder_models--en--ljspeech--univnet\\scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: univnet_generator\n",
      " > Discriminator Model: univnet_discriminator\n",
      " > Text splitted to sentences.\n",
      "['Would such an act of refusal be useful?']\n",
      "w äd s åtÕ° É …ôn √¶kt …ôv …π…™fjuz…ôl bi jusf…ôl?\n",
      " [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 2.3145246505737305\n",
      " > Real-time factor: 0.8069072309820192\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
      " > tts_models/en/ljspeech/glow-tts is already downloaded.\n",
      " > vocoder_models/en/ljspeech/multiband-melgan is already downloaded.\n",
      " > Using model: glow_tts\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.1\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Vocoder Model: multiband_melgan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:C:\\Users\\Admin\\AppData\\Local\\tts\\vocoder_models--en--ljspeech--multiband-melgan\\scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: multiband_melgan_generator\n",
      " > Discriminator Model: melgan_multiscale_discriminator\n",
      " > Text splitted to sentences.\n",
      "['Would such an act of refusal be useful?']\n",
      "w äd s åtÕ° É …ôn √¶kt …ôv …π…™fjuz…ôl bi jusf…ôl?\n",
      " [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 0.8417470455169678\n",
      " > Real-time factor: 0.2756076614642602\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
      " > tts_models/en/ljspeech/speedy-speech is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: speedy_speech\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      " > Text splitted to sentences.\n",
      "['Would such an act of refusal be useful?']\n",
      "w äd s åtÕ° É …ôn √¶kt …ôv …π…™fjuz…ôl bi jusf…ôl?\n",
      " [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 0.9584441184997559\n",
      " > Real-time factor: 0.3126285919070949\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
      " > tts_models/en/ljspeech/tacotron2-DCA is already downloaded.\n",
      " > vocoder_models/en/ljspeech/multiband-melgan is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:C:\\Users\\Admin\\AppData\\Local\\tts\\tts_models--en--ljspeech--tacotron2-DCA\\scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Model's reduction rate `r` is set to: 2\n",
      " > Vocoder Model: multiband_melgan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:0\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:50.0\n",
      " | > mel_fmax:7600.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:C:\\Users\\Admin\\AppData\\Local\\tts\\vocoder_models--en--ljspeech--multiband-melgan\\scale_stats.npy\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: multiband_melgan_generator\n",
      " > Discriminator Model: melgan_multiscale_discriminator\n",
      " > Text splitted to sentences.\n",
      "['Would such an act of refusal be useful?']\n",
      "w äd s åtÕ° É …ôn √¶kt …ôv …π…™fjuz…ôl bi jusf…ôl?\n",
      " [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 1.3958542346954346\n",
      " > Real-time factor: 0.5389917672148069\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.03 seconds.\n",
      " > tts_models/en/ljspeech/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " [!] No espeak backend found. Install espeak-ng or espeak to your system.\n",
      "Failed to load tacotron2-DCA.\n",
      " > tts_models/en/ljspeech/vits--neon is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " [!] No espeak backend found. Install espeak-ng or espeak to your system.\n",
      "Failed to load tacotron2-DCA.\n",
      " > tts_models/en/ljspeech/fast_pitch is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: fast_pitch\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Vocoder Model: hifigan\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Generator Model: hifigan_generator\n",
      " > Discriminator Model: hifigan_discriminator\n",
      "Removing weight norm...\n",
      " > Text splitted to sentences.\n",
      "['Would such an act of refusal be useful?']\n",
      "w äd s åtÕ° É …ôn √¶kt …ôv …π…™fjuz…ôl bi jusf…ôl?\n",
      " [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n",
      " > Processing time: 1.283581256866455\n",
      " > Real-time factor: 0.3947635393035223\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.03 seconds.\n",
      " > tts_models/en/ljspeech/overflow is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: OverFlow\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " [!] No espeak backend found. Install espeak-ng or espeak to your system.\n",
      "Failed to load fast_pitch.\n",
      " > tts_models/en/ljspeech/neural_hmm is already downloaded.\n",
      " > vocoder_models/en/ljspeech/hifigan_v2 is already downloaded.\n",
      " > Using model: NeuralHMM_TTS\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " [!] No espeak backend found. Install espeak-ng or espeak to your system.\n",
      "Failed to load fast_pitch.\n",
      " > tts_models/en/vctk/vits is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:1024\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " [!] No espeak backend found. Install espeak-ng or espeak to your system.\n",
      "Failed to load fast_pitch.\n",
      " > tts_models/en/vctk/fast_pitch is already downloaded.\n",
      " > Using model: fast_pitch\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:23\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " > Init speaker_embedding layer.\n",
      "Model is multi-speaker but no `speaker` is provided.\n",
      "Failed to load fast_pitch.\n",
      " > tts_models/en/sam/tacotron-DDC is already downloaded.\n",
      " > vocoder_models/en/sam/hifigan_v2 is already downloaded.\n",
      " > Using model: Tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:16000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:C:\\Users\\Admin\\AppData\\Local\\tts\\tts_models--en--sam--tacotron-DDC\\scale_stats.npy\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " [!] No espeak backend found. Install espeak-ng or espeak to your system.\n",
      "Failed to load fast_pitch.\n",
      " > tts_models/en/blizzard2013/capacitron-t2-c50 is already downloaded.\n",
      " > vocoder_models/en/blizzard2013/hifigan_v2 is already downloaded.\n",
      " > Using model: tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:24000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:80.0\n",
      " | > mel_fmax:12000.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:25.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " [!] No espeak backend found. Install espeak-ng or espeak to your system.\n",
      "Failed to load fast_pitch.\n",
      " > tts_models/en/blizzard2013/capacitron-t2-c150_v2 is already downloaded.\n",
      " > vocoder_models/en/blizzard2013/hifigan_v2 is already downloaded.\n",
      " > Using model: tacotron2\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:24000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:80.0\n",
      " | > mel_fmax:12000.0\n",
      " | > pitch_fmin:0.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:25.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " [!] No espeak backend found. Install espeak-ng or espeak to your system.\n",
      "Failed to load fast_pitch.\n",
      " > tts_models/en/multi-dataset/tortoise-v2 is already downloaded.\n",
      " [!] Config for tortoise cannot be found.\n",
      "Failed to load fast_pitch.\n",
      " > tts_models/en/jenny/jenny is already downloaded.\n",
      " > Using model: vits\n",
      " > Setting up Audio Processor...\n",
      " | > sample_rate:48000\n",
      " | > resample:False\n",
      " | > num_mels:100\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:0\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:None\n",
      " | > fft_size:2048\n",
      " | > power:None\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:None\n",
      " | > signal_norm:None\n",
      " | > symmetric_norm:None\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:None\n",
      " | > pitch_fmax:None\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:1.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:False\n",
      " | > trim_db:60\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:512\n",
      " | > win_length:2048\n",
      " > Text splitted to sentences.\n",
      "['Would such an act of refusal be useful?']\n",
      " > Processing time: 15.464974641799927\n",
      " > Real-time factor: 5.11351525684997\n",
      " > voice_conversion_models/multilingual/vctk/freevc24 is already downloaded.\n",
      " > Using model: freevc\n",
      " > Loading pretrained speaker encoder model ...\n",
      "Loaded the voice encoder model on cpu in 0.02 seconds.\n"
     ]
    }
   ],
   "source": [
    "en_models = [model for model in TTS.list_models() if '/en/' in model]\n",
    "# TTS with on the fly voice conversion\n",
    "for model in en_models:\n",
    "    try:\n",
    "        en_tts = TTS(model)\n",
    "        model_name = model.split('/')[-1]\n",
    "        en_tts.tts_with_vc_to_file(\n",
    "            source_text,\n",
    "            speaker_wav=str(target_audio_path),\n",
    "            file_path=output_folder / f'{model_name}_{output_filename}'\n",
    "        )\n",
    "    except Exception  as e:\n",
    "        print(e)\n",
    "        print(f'Failed to load {model_name}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate results in D:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other VC models:\n",
    "\n",
    "https://paperswithcode.com/task/voice-conversion\n",
    "=>\n",
    "https://github.com/bshall/VectorQuantizedCPC\n",
    "https://github.com/bshall/knn-vc\n",
    "\n",
    "neural network-based voice conversion model, such as CycleGAN, StarGAN-VC, or Tacotron 2\n",
    "\n",
    "VITS\n",
    "\n",
    "VALL-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-1. speech to text using the output file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://github.com/facebookresearch/fairseq/blob/main/examples/mms/asr/tutorial/MMS_ASR_Inference_Colab.ipynb\n",
    "* 4: Run Inference and transcribe your audio(s)\n",
    "\n",
    "To improve the transcription quality, user can use language-model (LM) decoding by following this instruction <a href='https://github.com/facebookresearch/fairseq/tree/main/examples/mms#asr'>ASR LM decoding</a>\n",
    "\n",
    "<br><br>\n",
    "2. https://github.com/facebookresearch/fairseq/blob/main/examples/mms/lid/tutorial/MMS_LID_Inference_Colab.ipynb\n",
    "* 4: Run Inference and transcribe your audio(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pick up one or two files for EDA since typically audio files are very heavy. do not pick up more than 5 files at a time, which might not be even possible.\n",
    "\n",
    "- Can try these to deal with the volume and high dimensionality of audio data:\n",
    "1) Google Colab\n",
    "2) Keras Audio data loading\n",
    "https://keras.io/api/data_loading/audio/#audio_dataset_from_directory-function\n",
    "\n",
    "\n",
    "- will need a library that converts audio files to machine-readable data, i.e. numbers.\n",
    "- will need another library that trains a model (e.g. sequence/ deep learning model for time series audio data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
