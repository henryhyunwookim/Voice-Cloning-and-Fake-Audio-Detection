{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "### <b>Table of Content</b>\n",
    "\n",
    "0. Background\n",
    "\n",
    "1. Import functions\n",
    "\n",
    "2. Load data\n",
    "\n",
    "3. Explore data<br>\n",
    "    3-1. Examine and transform data formats<br>\n",
    "    3-2. Plot histograms and box plots<br>\n",
    "    3-3. Plot a correlation heatmap<br>\n",
    "    3-4. Plot seasonal decomposition<br>\n",
    "    3-5. Plot autocorrelations\n",
    "\n",
    "3. build a classification model to access the performance of cloned audio's target speaker\n",
    "    3-1. Convert .wav to machine-readable form\n",
    "    3-2. train a model\n",
    "    3-3. evaluate classification accuracy using test data\n",
    "\n",
    "4. first, build a voice cloning system given a speaker‚Äôs spoken audio that clones the source speaker‚Äôs voice to the target speaker‚Äôs voice<br>\n",
    "    4-1. For the voice cloning system (VC), you can utilize the TIMIT dataset as it consists of aligned text-audio data with various speakers.<br>\n",
    "    4-2. Use Word Error Rate (WER) for automatic evaluation of the voice cloning (VC) system for the speech generation part<br>\n",
    "    &emsp; 4-2-1. speech to text<br>\n",
    "    &emsp; 4-2-2. measure WER using the original script and transcribed text<br>\n",
    "    4-3. also report speaker classification accuracy to assess the performance of the generated audio‚Äôs target speaker.\n",
    "\n",
    "5. Next, build a machine learning system which detects if any spoken audio is a natural speech or synthetically generated by machine.<br>\n",
    "    5-1. For the fake audio detection system (FAD) you can utilize the CommonVoice dataset as it consists of thousands of naturally spoken audio which could be used as golden spoken audio by humans as positive examples and creating negative examples using the voice cloning system as automatic data/label generator.<br>\n",
    "    5-2. For the fake audio detection (FAD) system evaluate the performance of the models using F-score via positive labels coming from the groundtruth dataset and negative labels generated by the VC.\n",
    "\n",
    "\n",
    "\n",
    "4. Select and engineer features\n",
    "\n",
    "5. Train models<br>\n",
    "    5-1. Split data into train and test sets<br>\n",
    "    5-2. SARIMAX model<br>\n",
    "    &emsp; 5-2-1. Perform stepwise search<br>\n",
    "    &emsp; 5-2-2. Train with best orders<br>\n",
    "    5-3. Train and evaluate different models<br>\n",
    "    &emsp; 5-3-1. Train three different models<br>\n",
    "    &emsp; 5-3-2. Compare model performance\n",
    "\n",
    "6. Evaluate prediction results<br>\n",
    "    6-1. Create Bollinger Bands<br>\n",
    "    6-2. Get trading dates with different intervals<br>\n",
    "    6-3. Make training decisions and get capital returns<br>\n",
    "    &emsp; 6-3-1. Based on SARIMAX predictions<br>\n",
    "    &emsp; 6-3-2. Based on Bollinger Band\n",
    "\n",
    "7. Build pipeline and process all stock data<br>\n",
    "    7-1. Interpret results<br>\n",
    "    &emsp; 7-1-1. Capital returns<br>\n",
    "    &emsp; 7-1-2. Model performance\n",
    "\n",
    "8. Conclusion\n",
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>0. Background</b>\n",
    "\n",
    "This project is for a cyber security company providing products and services that can detect whether audio and video media is authentic or fake.\n",
    "\n",
    "We are given two publically available corpora of speech data, which are the <a href=\"https://github.com/philipperemy/timit\">TIMIT</a> and <a href=\"https://commonvoice.mozilla.org/en/datasets\">CommonVoice</a> datasets. We will build two machine learning systems using these datasets as follows:\n",
    "\n",
    "1. A voice cloning (VC) system that clones a given speaker's spoken audio to the target speaker's voice.\n",
    "2. A fake audio detection (FAD) system that detects if any spoken audio is natural speech or synthetically generated by machines.\n",
    "\n",
    "More details can be found in <a href=\"https://github.com/henryhyunwookim/K7h2vHrgG1Gl0S2r#readme\">README</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>1. Import functions</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS\n",
    "# https://tts.readthedocs.io/en/latest/inference.html\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2. Load data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file path.\n",
    "root_dir = Path(sys.path[0])\n",
    "\n",
    "timit_dir = root_dir / 'data' / 'TIMIT' / 'archive'\n",
    "common_voice_dir = root_dir / 'data' / 'CommonVoice' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23-en.tar' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23-en' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23' / 'en' / 'clips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_or_train</th>\n",
       "      <th>dialect_region</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>path_from_data_dir</th>\n",
       "      <th>path_from_data_dir_windows</th>\n",
       "      <th>is_converted_audio</th>\n",
       "      <th>is_audio</th>\n",
       "      <th>is_word_file</th>\n",
       "      <th>is_phonetic_file</th>\n",
       "      <th>is_sentence_file</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI681.WAV.wav</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI681.WAV.wav</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SI1311.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SI1311.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.PHN</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.PHN</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRAIN</td>\n",
       "      <td>DR4</td>\n",
       "      <td>MMDM0</td>\n",
       "      <td>SX321.WRD</td>\n",
       "      <td>TRAIN/DR4/MMDM0/SX321.WRD</td>\n",
       "      <td>TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      test_or_train dialect_region speaker_id       filename  \\\n",
       "index                                                          \n",
       "1             TRAIN            DR4      MMDM0  SI681.WAV.wav   \n",
       "2             TRAIN            DR4      MMDM0     SI1311.PHN   \n",
       "3             TRAIN            DR4      MMDM0     SI1311.WRD   \n",
       "4             TRAIN            DR4      MMDM0      SX321.PHN   \n",
       "5             TRAIN            DR4      MMDM0      SX321.WRD   \n",
       "\n",
       "                  path_from_data_dir        path_from_data_dir_windows  \\\n",
       "index                                                                    \n",
       "1      TRAIN/DR4/MMDM0/SI681.WAV.wav  TRAIN\\\\DR4\\\\MMDM0\\\\SI681.WAV.wav   \n",
       "2         TRAIN/DR4/MMDM0/SI1311.PHN     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.PHN   \n",
       "3         TRAIN/DR4/MMDM0/SI1311.WRD     TRAIN\\\\DR4\\\\MMDM0\\\\SI1311.WRD   \n",
       "4          TRAIN/DR4/MMDM0/SX321.PHN      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.PHN   \n",
       "5          TRAIN/DR4/MMDM0/SX321.WRD      TRAIN\\\\DR4\\\\MMDM0\\\\SX321.WRD   \n",
       "\n",
       "      is_converted_audio is_audio is_word_file is_phonetic_file  \\\n",
       "index                                                             \n",
       "1                   True     True        False            False   \n",
       "2                  False    False        False             True   \n",
       "3                  False    False         True            False   \n",
       "4                  False    False        False             True   \n",
       "5                  False    False         True            False   \n",
       "\n",
       "      is_sentence_file  \n",
       "index                   \n",
       "1                False  \n",
       "2                False  \n",
       "3                False  \n",
       "4                False  \n",
       "5                False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv = pd.read_csv(timit_dir / 'train_data.csv', index_col='index').dropna(how='all')\n",
    "train_csv.index = train_csv.index.astype(int).astype(str)\n",
    "\n",
    "test_csv = pd.read_csv(timit_dir / 'test_data.csv', index_col='index').dropna(how='any')\n",
    "test_csv.index = test_csv.index.astype(int).astype(str)\n",
    "\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path: d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\data\\TIMIT\\archive\\data\\TRAIN\\DR4\\MMDM0\\SI681.WAV.wav\n",
      "Target path: d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\data\\TIMIT\\archive\\data\\TRAIN\\DR8\\MRDM0\\SA2.WAV.wav\n"
     ]
    }
   ],
   "source": [
    "train_audio_path = train_csv[train_csv['is_converted_audio']==True]['path_from_data_dir']\n",
    "\n",
    "source_audio_subpath = train_audio_path[0]\n",
    "source_speaker_id = source_audio_subpath.split('/')[2]\n",
    "source_audio_file = source_audio_subpath.split('/')[3]\n",
    "source_file_id = source_audio_file.split('.')[0]\n",
    "source_audio_path = timit_dir / 'data' / source_audio_subpath\n",
    "\n",
    "import string\n",
    "source_text_subpath = train_csv[(train_csv['speaker_id']==source_speaker_id) &\n",
    "          (train_csv['filename']==source_file_id+'.TXT')]['path_from_data_dir'][0]\n",
    "source_text_file = source_text_subpath.split('/')[3]\n",
    "source_text_path = timit_dir / 'data' / source_text_subpath\n",
    "with open(source_text_path) as txt:\n",
    "    raw_source_text = txt.read().split()[2:]\n",
    "source_text = ' '.join(raw_source_text) # Remove whitespace\n",
    "source_text = source_text.translate(str.maketrans('', '', string.punctuation)) # Remove punctuation\n",
    "source_text = source_text.lower() # Convert to lowercase\n",
    "print(f'Source path: {source_audio_path}')\n",
    "\n",
    "target_audio_subpath = train_audio_path[-1]\n",
    "target_speaker_id = target_audio_subpath.split('/')[2]\n",
    "target_audio_file = target_audio_subpath.split('/')[3]\n",
    "target_file_id = target_audio_file.split('.')[0]\n",
    "target_audio_path = timit_dir / 'data' / target_audio_subpath\n",
    "print(f'Target path: {target_audio_path}')\n",
    "\n",
    "output_folder = root_dir / 'output' / f'{source_speaker_id}-{source_file_id}_to_{target_speaker_id}-{target_file_id}'\n",
    "output_filename = f'{source_speaker_id}-{source_file_id}_to_{target_speaker_id}-{target_file_id}.wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. clone audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy original source and target files to the destination folder\n",
    "# for an easier review of the output file.\n",
    "from shutil import copy2\n",
    "import os\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n",
    "\n",
    "# Copy with file permission and dest can be a folder\n",
    "if not os.path.exists(output_folder / source_audio_file):\n",
    "    copy2(src=source_audio_path, dst=output_folder / source_audio_file)\n",
    "if not os.path.exists(output_folder / target_audio_file):\n",
    "    copy2(src=target_audio_path, dst=output_folder / target_audio_file)\n",
    "if not os.path.exists(output_folder / source_text_file):\n",
    "    copy2(src=source_text_path, dst=output_folder / source_text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\multi_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n"
     ]
    }
   ],
   "source": [
    "# Example voice conversion converting speaker of the source_wav to the speaker of the target_wav\n",
    "# Downloading model to C:\\Users\\Admin\\AppData\\Local\\tts\\voice_conversion_models--multilingual--vctk--freevc24   \n",
    "multi_output_path = output_folder / f'multi_{output_filename}'\n",
    "if os.path.exists(multi_output_path):\n",
    "    print(f'{multi_output_path} already exists.')\n",
    "else:\n",
    "    multi_tts = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False, gpu=False)\n",
    "    multi_tts.voice_conversion_to_file(\n",
    "        source_wav=str(source_audio_path),\n",
    "        target_wav=str(target_audio_path),\n",
    "        file_path=multi_output_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No API token found for üê∏Coqui Studio voices - https://coqui.ai \n",
      "Visit üîóhttps://app.coqui.ai/account to get one.\n",
      "Set it as an environment variable `export COQUI_STUDIO_TOKEN=<token>`\n",
      "\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\tacotron2_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\tacotron2-DDC_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\tacotron2-DDC_ph_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\glow-tts_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\speedy-speech_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\tacotron2-DCA_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\vits_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\vits--neon_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\fast_pitch_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\overflow_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\neural_hmm_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\vits_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\fast_pitch_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\tacotron-DDC_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\capacitron-t2-c50_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\capacitron-t2-c150_v2_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n",
      " > tts_models/en/multi-dataset/tortoise-v2 is already downloaded.\n",
      " [!] Config for tortoise cannot be found.\n",
      "Failed to load tortoise-v2.\n",
      "d:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2\\jenny_MMDM0-SI681_to_MRDM0-SA2.wav already exists.\n"
     ]
    }
   ],
   "source": [
    "# TTS with on the fly voice conversion\n",
    "en_models = [model for model in TTS.list_models() if '/en/' in model]\n",
    "for model in en_models:\n",
    "    try:\n",
    "        model_name = model.split('/')[-1]\n",
    "        output_file_path = output_folder / f'{model_name}_{output_filename}'\n",
    "        if os.path.exists(output_file_path):\n",
    "            print(f'{output_file_path} already exists.')\n",
    "        else:\n",
    "            en_tts = TTS(model)\n",
    "            en_tts.tts_with_vc_to_file(\n",
    "                source_text,\n",
    "                speaker_wav=str(target_audio_path),\n",
    "                file_path=output_file_path\n",
    "            )\n",
    "    except Exception  as e:\n",
    "        print(e)\n",
    "        print(f'Failed to load {model_name}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate results in D:\\OneDrive\\GitHub\\Apziva\\K7h2vHrgG1Gl0S2r\\output\\MMDM0-SI681_to_MRDM0-SA2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3-1. speech to text using the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: what's such an act of refuse to be used for\n",
      "Performance of model \"capacitron-t2-c150\":\n",
      "sentence 1\n",
      "REF:  would such an act of ****** refusal be **** useful\n",
      "HYP: what's such an act of refuse      to be used    for\n",
      "          S                     I       S       I      S\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=3 deletions=0 insertions=2 hits=5\n",
      "\n",
      "mer=50.00%\n",
      "wil=68.75%\n",
      "wip=31.25%\n",
      "wer=62.50%\n",
      "\n",
      "sentence 1\n",
      "REF: w*ould such an act of refus**al be use**ful\n",
      "HYP: what's such an act of refuse to be used for\n",
      "      ISSSS                     IISS       II SS\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=8 deletions=0 insertions=5 hits=30\n",
      "\n",
      "cer=34.21%\n",
      "\n",
      "\n",
      "Transcription: what's such an act of refusal be useful\n",
      "Performance of model \"capacitron-t2-c50\":\n",
      "sentence 1\n",
      "REF:  would such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "          S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: w*ould such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "      ISSSS                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=4 deletions=0 insertions=1 hits=34\n",
      "\n",
      "cer=13.16%\n",
      "\n",
      "\n",
      "Transcription: I would such an act of refusal be useful in\n",
      "Performance of model \"fast\":\n",
      "sentence 1\n",
      "REF: * would such an act of refusal be useful **\n",
      "HYP: I would such an act of refusal be useful in\n",
      "     I                                         I\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=2 hits=8\n",
      "\n",
      "mer=20.00%\n",
      "wil=20.00%\n",
      "wip=80.00%\n",
      "wer=25.00%\n",
      "\n",
      "sentence 1\n",
      "REF: **would such an act of refusal be useful***\n",
      "HYP: I would such an act of refusal be useful in\n",
      "     II                                      III\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=5 hits=38\n",
      "\n",
      "cer=13.16%\n",
      "\n",
      "\n",
      "Transcription: was such an act of refusal be useful\n",
      "Performance of model \"glow-tts\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP:   was such an act of refusal be useful\n",
      "         S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: was** such an act of refusal be useful\n",
      "      SSDD                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=2 deletions=2 insertions=0 hits=34\n",
      "\n",
      "cer=10.53%\n",
      "\n",
      "\n",
      "Transcription: was such an act of refusal be useful\n",
      "Performance of model \"jenny\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP:   was such an act of refusal be useful\n",
      "         S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: was** such an act of refusal be useful\n",
      "      SSDD                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=2 deletions=2 insertions=0 hits=34\n",
      "\n",
      "cer=10.53%\n",
      "\n",
      "\n",
      "Transcription: with such an act of refusal be used\n",
      "Performance of model \"multi\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP:  with such an act of refusal be   used\n",
      "         S                                S\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=2 deletions=0 insertions=0 hits=6\n",
      "\n",
      "mer=25.00%\n",
      "wil=43.75%\n",
      "wip=56.25%\n",
      "wer=25.00%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: with* such an act of refusal be used**\n",
      "      SSSD                              SDD\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=4 deletions=3 insertions=0 hits=31\n",
      "\n",
      "cer=18.42%\n",
      "\n",
      "\n",
      "Transcription: would such an act of refusal be useful\n",
      "Performance of model \"neural\":\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=8\n",
      "\n",
      "mer=0.00%\n",
      "wil=0.00%\n",
      "wip=100.00%\n",
      "wer=0.00%\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=38\n",
      "\n",
      "cer=0.00%\n",
      "\n",
      "\n",
      "Transcription: would such an act of refusal be useful\n",
      "Performance of model \"overflow\":\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=8\n",
      "\n",
      "mer=0.00%\n",
      "wil=0.00%\n",
      "wip=100.00%\n",
      "wer=0.00%\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=38\n",
      "\n",
      "cer=0.00%\n",
      "\n",
      "\n",
      "Transcription: would such an act of refusal be used to\n",
      "Performance of model \"speedy-speech\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be **** useful\n",
      "HYP: would such an act of refusal be used     to\n",
      "                                        I      S\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=1 hits=7\n",
      "\n",
      "mer=22.22%\n",
      "wil=31.94%\n",
      "wip=68.06%\n",
      "wer=25.00%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be use*ful\n",
      "HYP: would such an act of refusal be used to\n",
      "                                        ISSS\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=3 deletions=0 insertions=1 hits=35\n",
      "\n",
      "cer=10.53%\n",
      "\n",
      "\n",
      "Transcription: Wasatch an act of refusal be useful\n",
      "Performance of model \"tacotron-DDC\":\n",
      "sentence 1\n",
      "REF:   would such an act of refusal be useful\n",
      "HYP: Wasatch **** an act of refusal be useful\n",
      "           S    D                            \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=1 insertions=0 hits=6\n",
      "\n",
      "mer=25.00%\n",
      "wil=35.71%\n",
      "wip=64.29%\n",
      "wer=25.00%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: Wasat***ch an act of refusal be useful\n",
      "     SSSSSDDD                              \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=5 deletions=3 insertions=0 hits=30\n",
      "\n",
      "cer=21.05%\n",
      "\n",
      "\n",
      "Transcription: would such an active refusal be useful\n",
      "Performance of model \"tacotron2-DCA\":\n",
      "sentence 1\n",
      "REF: would such an    act of refusal be useful\n",
      "HYP: would such an active ** refusal be useful\n",
      "                        S  D                  \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=1 insertions=0 hits=6\n",
      "\n",
      "mer=25.00%\n",
      "wil=35.71%\n",
      "wip=64.29%\n",
      "wer=25.00%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: would such an active refusal be useful\n",
      "                      SSS                  \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=3 deletions=0 insertions=0 hits=35\n",
      "\n",
      "cer=7.89%\n",
      "\n",
      "\n",
      "Transcription: would such an act of refusal be useful\n",
      "Performance of model \"tacotron2-DDC\":\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=8\n",
      "\n",
      "mer=0.00%\n",
      "wil=0.00%\n",
      "wip=100.00%\n",
      "wer=0.00%\n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=0 deletions=0 insertions=0 hits=38\n",
      "\n",
      "cer=0.00%\n",
      "\n",
      "\n",
      "Transcription: what's such an act of refusal be useful\n",
      "Performance of model \"tacotron2-DDC\":\n",
      "sentence 1\n",
      "REF:  would such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "          S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: w*ould such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "      ISSSS                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=4 deletions=0 insertions=1 hits=34\n",
      "\n",
      "cer=13.16%\n",
      "\n",
      "\n",
      "Transcription: with such an act of refusal be useful\n",
      "Performance of model \"tacotron2\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP:  with such an act of refusal be useful\n",
      "         S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: with* such an act of refusal be useful\n",
      "      SSSD                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=3 deletions=1 insertions=0 hits=34\n",
      "\n",
      "cer=10.53%\n",
      "\n",
      "\n",
      "Transcription: put such an act of refusal be useful\n",
      "Performance of model \"vits--neon\":\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP:   put such an act of refusal be useful\n",
      "         S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: would such an act of refusal be useful\n",
      "HYP: p*ut* such an act of refusal be useful\n",
      "     SD SD                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=2 deletions=2 insertions=0 hits=34\n",
      "\n",
      "cer=10.53%\n",
      "\n",
      "\n",
      "Transcription: what's such an act of refusal be useful\n",
      "Performance of model \"vits\":\n",
      "sentence 1\n",
      "REF:  would such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "          S                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=1 deletions=0 insertions=0 hits=7\n",
      "\n",
      "mer=12.50%\n",
      "wil=23.44%\n",
      "wip=76.56%\n",
      "wer=12.50%\n",
      "\n",
      "sentence 1\n",
      "REF: w*ould such an act of refusal be useful\n",
      "HYP: what's such an act of refusal be useful\n",
      "      ISSSS                                 \n",
      "\n",
      "number of sentences: 1\n",
      "substitutions=4 deletions=0 insertions=1 hits=34\n",
      "\n",
      "cer=13.16%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://pdf.co/blog/transcribe-speech-recordings-to-text-python\n",
    "\n",
    "import speech_recognition as sr\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "from jiwer import process_words, process_characters, visualize_alignment\n",
    "\n",
    "eval_dict = {}\n",
    "for filename in os.listdir(output_folder):\n",
    "    if output_filename in filename:\n",
    "        wav_path = output_folder / filename\n",
    "        model_name = filename.split('/')[-1].split('_')[0]\n",
    "        # sound=AudioSegment.from_wav(wav_path)\n",
    "        r=sr.Recognizer()\n",
    "        with sr.AudioFile(str(wav_path)) as source:\n",
    "            audio=r.record(source)\n",
    "            transcription = r.recognize_google(audio, language='en-US')\n",
    "            print(f'Transcription: {transcription}')\n",
    "\n",
    "        eval_dict[model_name] = {}\n",
    "        words_output = process_words(source_text, transcription) # source_text and transcription can be either a string or a list of strings\n",
    "        eval_dict[model_name]['wer'] = words_output.wer\n",
    "        eval_dict[model_name]['mer'] = words_output.mer\n",
    "        eval_dict[model_name]['wil'] = words_output.wil\n",
    "        eval_dict[model_name]['wip'] = words_output.wip\n",
    "\n",
    "        chars_output = process_characters(source_text, transcription)\n",
    "        eval_dict[model_name]['cer'] = chars_output.cer\n",
    "        eval_dict[model_name]['Transcription'] = transcription\n",
    "        \n",
    "        print(f'Performance of model \"{model_name}\":')\n",
    "        print(visualize_alignment(words_output))\n",
    "        print(visualize_alignment(chars_output))\n",
    "        print()\n",
    "\n",
    "        # Saving the Transcript\n",
    "        # transcription_path = output_folder / filename.replace('.wav', '.txt')\n",
    "        # if os.path.exists(transcription_path):\n",
    "        #     print(f'{transcription_path} already exists.')\n",
    "        # else:\n",
    "        #     with open(transcription_path, \"w\") as file:\n",
    "        #         file.write(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source text: would such an act of refusal be useful\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wer</th>\n",
       "      <th>mer</th>\n",
       "      <th>wil</th>\n",
       "      <th>wip</th>\n",
       "      <th>cer</th>\n",
       "      <th>Transcription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neural</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>would such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overflow</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>would such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glow-tts</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>was such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jenny</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>was such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tacotron2</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>with such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vits--neon</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>put such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capacitron-t2-c50</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>what's such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tacotron2-DDC</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>what's such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vits</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>what's such an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>I would such an act of refusal be useful in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speedy-speech</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>would such an act of refusal be used to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tacotron2-DCA</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>would such an active refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tacotron-DDC</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>Wasatch an act of refusal be useful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>with such an act of refusal be used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capacitron-t2-c150</th>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>what's such an act of refuse to be used for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      wer       mer       wil       wip       cer  \\\n",
       "neural                0.0       0.0       0.0       1.0       0.0   \n",
       "overflow              0.0       0.0       0.0       1.0       0.0   \n",
       "glow-tts            0.125     0.125  0.234375  0.765625  0.105263   \n",
       "jenny               0.125     0.125  0.234375  0.765625  0.105263   \n",
       "tacotron2           0.125     0.125  0.234375  0.765625  0.105263   \n",
       "vits--neon          0.125     0.125  0.234375  0.765625  0.105263   \n",
       "capacitron-t2-c50   0.125     0.125  0.234375  0.765625  0.131579   \n",
       "tacotron2-DDC       0.125     0.125  0.234375  0.765625  0.131579   \n",
       "vits                0.125     0.125  0.234375  0.765625  0.131579   \n",
       "fast                 0.25       0.2       0.2       0.8  0.131579   \n",
       "speedy-speech        0.25  0.222222  0.319444  0.680556  0.105263   \n",
       "tacotron2-DCA        0.25      0.25  0.357143  0.642857  0.078947   \n",
       "tacotron-DDC         0.25      0.25  0.357143  0.642857  0.210526   \n",
       "multi                0.25      0.25    0.4375    0.5625  0.184211   \n",
       "capacitron-t2-c150  0.625       0.5    0.6875    0.3125  0.342105   \n",
       "\n",
       "                                                  Transcription  \n",
       "neural                   would such an act of refusal be useful  \n",
       "overflow                 would such an act of refusal be useful  \n",
       "glow-tts                   was such an act of refusal be useful  \n",
       "jenny                      was such an act of refusal be useful  \n",
       "tacotron2                 with such an act of refusal be useful  \n",
       "vits--neon                 put such an act of refusal be useful  \n",
       "capacitron-t2-c50       what's such an act of refusal be useful  \n",
       "tacotron2-DDC           what's such an act of refusal be useful  \n",
       "vits                    what's such an act of refusal be useful  \n",
       "fast                I would such an act of refusal be useful in  \n",
       "speedy-speech           would such an act of refusal be used to  \n",
       "tacotron2-DCA            would such an active refusal be useful  \n",
       "tacotron-DDC                Wasatch an act of refusal be useful  \n",
       "multi                       with such an act of refusal be used  \n",
       "capacitron-t2-c150  what's such an act of refuse to be used for  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Source text: {source_text}')\n",
    "eval_df = pd.DataFrame(eval_dict).T\n",
    "eval_df.sort_values(list(eval_df.columns)[:-1], ascending=[True, True, True, False, True])\n",
    "\n",
    "# The following measures are implemented:\n",
    "# 1. Word Error Rate (WER), which is where this library got its name from. This\n",
    "#   has long been (and arguably still is) the de facto standard for computing\n",
    "#   ASR performance. - the lower the better (i.e. more accurate)\n",
    "# 2. Match Error Rate (MER) - the lower the better (i.e. more accurate)\n",
    "# 3. Word Information Lost (WIL) - the lower the better (i.e. more accurate)\n",
    "# 4. Word Information Preserved (WIP) - the larget the better\n",
    "# 5. Character Error Rate (CER) - the lower the better (i.e. more accurate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build an audio classification model to predict the speaker based on synthesized audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other VC models:\n",
    "\n",
    "https://paperswithcode.com/task/voice-conversion\n",
    "=>\n",
    "https://github.com/bshall/VectorQuantizedCPC\n",
    "https://github.com/bshall/knn-vc\n",
    "\n",
    "neural network-based voice conversion model, such as CycleGAN, StarGAN-VC, or Tacotron 2\n",
    "\n",
    "VITS\n",
    "\n",
    "VALL-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pick up one or two files for EDA since typically audio files are very heavy. do not pick up more than 5 files at a time, which might not be even possible.\n",
    "\n",
    "- Can try these to deal with the volume and high dimensionality of audio data:\n",
    "1) Google Colab\n",
    "2) Keras Audio data loading\n",
    "https://keras.io/api/data_loading/audio/#audio_dataset_from_directory-function\n",
    "\n",
    "\n",
    "- will need a library that converts audio files to machine-readable data, i.e. numbers.\n",
    "- will need another library that trains a model (e.g. sequence/ deep learning model for time series audio data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
