{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------\n",
    "### <b>Table of Content</b>\n",
    "\n",
    "0. Background\n",
    "\n",
    "1. Import functions\n",
    "\n",
    "2. Load data\n",
    "\n",
    "3. Explore data<br>\n",
    "    3-1. Examine and transform data formats<br>\n",
    "    3-2. Plot histograms and box plots<br>\n",
    "    3-3. Plot a correlation heatmap<br>\n",
    "    3-4. Plot seasonal decomposition<br>\n",
    "    3-5. Plot autocorrelations\n",
    "\n",
    "4. Select and engineer features\n",
    "\n",
    "5. Train models<br>\n",
    "    5-1. Split data into train and test sets<br>\n",
    "    5-2. SARIMAX model<br>\n",
    "    &emsp; 5-2-1. Perform stepwise search<br>\n",
    "    &emsp; 5-2-2. Train with best orders<br>\n",
    "    5-3. Train and evaluate different models<br>\n",
    "    &emsp; 5-3-1. Train three different models<br>\n",
    "    &emsp; 5-3-2. Compare model performance\n",
    "\n",
    "6. Evaluate prediction results<br>\n",
    "    6-1. Create Bollinger Bands<br>\n",
    "    6-2. Get trading dates with different intervals<br>\n",
    "    6-3. Make training decisions and get capital returns<br>\n",
    "    &emsp; 6-3-1. Based on SARIMAX predictions<br>\n",
    "    &emsp; 6-3-2. Based on Bollinger Band\n",
    "\n",
    "7. Build pipeline and process all stock data<br>\n",
    "    7-1. Interpret results<br>\n",
    "    &emsp; 7-1-1. Capital returns<br>\n",
    "    &emsp; 7-1-2. Model performance\n",
    "\n",
    "8. Conclusion\n",
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>0. Background</b>\n",
    "\n",
    "This project is for a cyber security company providing products and services that can detect whether audio and video media is authentic or fake.\n",
    "\n",
    "We are given two publically available corpora of speech data, which are the <a href=\"https://github.com/philipperemy/timit\">TIMIT</a> and <a href=\"https://commonvoice.mozilla.org/en/datasets\">CommonVoice</a> datasets. We will build two machine learning systems using these datasets as follows:\n",
    "\n",
    "1. A voice cloning (VC) system that clones a given speaker's spoken audio to the target speaker's voice.\n",
    "2. A fake audio detection (FAD) system that detects if any spoken audio is natural speech or synthetically generated by machines.\n",
    "\n",
    "More details can be found in <a href=\"https://github.com/henryhyunwookim/K7h2vHrgG1Gl0S2r#readme\">README</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>1. Import functions</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>2. Load data</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Define file path.\n",
    "root_dir = Path(sys.path[0])\n",
    "\n",
    "timit_dir = root_dir / 'data' / 'TIMIT' / 'archive'\n",
    "common_voice_dir = root_dir / 'data' / 'CommonVoice' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23-en.tar' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23-en' / \\\n",
    "    'cv-corpus-14.0-delta-2023-06-23' / 'en' / 'clips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.api import TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://tts.readthedocs.io/en/latest/inference.html\n",
    "from TTS.api import TTS\n",
    "\n",
    "# List available üê∏TTS models and choose the first one\n",
    "model_name = TTS.list_models()[0]\n",
    "# Init TTS\n",
    "tts = TTS(model_name)\n",
    "# Run TTS\n",
    "# ‚ùó Since this model is multi-speaker and multi-lingual,\n",
    "# we must set the target speaker and the language\n",
    "\n",
    "# Text to speech with a numpy output\n",
    "wav = tts.tts(\"This is a test! This is also a test!!\",\n",
    "              speaker=tts.speakers[0],\n",
    "              language=tts.languages[0])\n",
    "\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=\"Hello world!\",\n",
    "                speaker=tts.speakers[0],\n",
    "                language=tts.languages[0],\n",
    "                file_path=\"output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://github.com/coqui-ai/tts\n",
    "https://tts.readthedocs.io/en/latest/inference.html\n",
    "\n",
    "\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Running a multi-speaker and multi-lingual model\n",
    "\n",
    "# List available üê∏TTS models and choose the first one\n",
    "model_name = TTS.list_models()[0]\n",
    "# Init TTS\n",
    "tts = TTS(model_name)\n",
    "\n",
    "# Run TTS\n",
    "\n",
    "# ‚ùó Since this model is multi-speaker and multi-lingual, we must set the target speaker and the language\n",
    "# Text to speech with a numpy output\n",
    "wav = tts.tts(\"This is a test! This is also a test!!\", speaker=tts.speakers[0], language=tts.languages[0])\n",
    "# Text to speech to a file\n",
    "tts.tts_to_file(text=\"Hello world!\", speaker=tts.speakers[0], language=tts.languages[0], file_path=\"output.wav\")\n",
    "\n",
    "# Running a single speaker model\n",
    "\n",
    "# Init TTS with the target model name\n",
    "tts = TTS(model_name=\"tts_models/de/thorsten/tacotron2-DDC\", progress_bar=False, gpu=False)\n",
    "# Run TTS\n",
    "tts.tts_to_file(text=\"Ich bin eine Testnachricht.\", file_path=OUTPUT_PATH)\n",
    "\n",
    "# Example voice cloning with YourTTS in English, French and Portuguese\n",
    "\n",
    "tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=False, gpu=True)\n",
    "tts.tts_to_file(\"This is voice cloning.\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")\n",
    "tts.tts_to_file(\"C'est le clonage de la voix.\", speaker_wav=\"my/cloning/audio.wav\", language=\"fr-fr\", file_path=\"output.wav\")\n",
    "tts.tts_to_file(\"Isso √© clonagem de voz.\", speaker_wav=\"my/cloning/audio.wav\", language=\"pt-br\", file_path=\"output.wav\")\n",
    "\n",
    "\n",
    "# Example voice conversion converting speaker of the `source_wav` to the speaker of the `target_wav`\n",
    "\n",
    "tts = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False, gpu=True)\n",
    "tts.voice_conversion_to_file(source_wav=\"my/source.wav\", target_wav=\"my/target.wav\", file_path=\"output.wav\")\n",
    "\n",
    "# Example voice cloning by a single speaker TTS model combining with the voice conversion model. This way, you can\n",
    "# clone voices by using any model in üê∏TTS.\n",
    "\n",
    "tts = TTS(\"tts_models/de/thorsten/tacotron2-DDC\")\n",
    "tts.tts_with_vc_to_file(\n",
    "    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n",
    "    speaker_wav=\"target/speaker.wav\",\n",
    "    file_path=\"output.wav\"\n",
    ")\n",
    "\n",
    "# Example text to speech using [üê∏Coqui Studio](https://coqui.ai) models.\n",
    "\n",
    "# You can use all of your available speakers in the studio.\n",
    "# [üê∏Coqui Studio](https://coqui.ai) API token is required. You can get it from the [account page](https://coqui.ai/account).\n",
    "# You should set the `COQUI_STUDIO_TOKEN` environment variable to use the API token.\n",
    "\n",
    "# If you have a valid API token set you will see the studio speakers as separate models in the list.\n",
    "# The name format is coqui_studio/en/<studio_speaker_name>/coqui_studio\n",
    "models = TTS().list_models()\n",
    "# Init TTS with the target studio speaker\n",
    "tts = TTS(model_name=\"coqui_studio/en/Torcull Diarmuid/coqui_studio\", progress_bar=False, gpu=False)\n",
    "# Run TTS\n",
    "tts.tts_to_file(text=\"This is a test.\", file_path=OUTPUT_PATH)\n",
    "# Run TTS with emotion and speed control\n",
    "tts.tts_to_file(text=\"This is a test.\", file_path=OUTPUT_PATH, emotion=\"Happy\", speed=1.5)\n",
    "\n",
    "\n",
    "#Example text to speech using **Fairseq models in ~1100 languages** ü§Ø.\n",
    "\n",
    "#For these models use the following name format: `tts_models/<lang-iso_code>/fairseq/vits`.\n",
    "#You can find the list of language ISO codes [here](https://dl.fbaipublicfiles.com/mms/tts/all-tts-languages.html) and learn about the Fairseq models [here](https://github.com/facebookresearch/fairseq/tree/main/examples/mms).\n",
    "\n",
    "# TTS with on the fly voice conversion\n",
    "api = TTS(\"tts_models/deu/fairseq/vits\")\n",
    "api.tts_with_vc_to_file(\n",
    "    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n",
    "    speaker_wav=\"target/speaker.wav\",\n",
    "    file_path=\"output.wav\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pick up one or two files for EDA since typically audio files are very heavy. do not pick up more than 5 files at a time, which might not be even possible.\n",
    "\n",
    "- Can try these to deal with the volume and high dimensionality of audio data:\n",
    "1) Google Colab\n",
    "2) Keras Audio data loading\n",
    "https://keras.io/api/data_loading/audio/#audio_dataset_from_directory-function\n",
    "\n",
    "\n",
    "- will need a library that converts audio files to machine-readable data, i.e. numbers.\n",
    "- will need another library that trains a model (e.g. sequence/ deep learning model for time series audio data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
